---
title: "Pr√°ctica 6"
date: 2025-09-19
---

# Pr√°ctica 6: Clustering y PCA - Mall Customer Segmentation

## Contexto

La actividad se centra en aplicar t√©cnicas de aprendizaje autom√°tico no supervisado para entender mejor el comportamiento de los clientes en centros comerciales. Utiliza el dataset "Mall Customer Segmentation" que contiene datos demogr√°ficos y de consumo de aproximadamente 200 clientes.

## Objetivos

- Identificar grupos de clientes con caracter√≠sticas similares usando K-Means Clustering.
- Reducir la dimensionalidad de los datos con PCA para facilitar la visualizaci√≥n.
- Comparar PCA con m√©todos de selecci√≥n de variables como Forward y Backward Selection.
- Evaluar la calidad de los clusters mediante m√©tricas como el Silhouette Score.
- Interpretar los perfiles de cada segmento desde una perspectiva de negocio.

## Actividades (con tiempos estimados)

- FASE 1: BUSINESS UNDERSTANDING
- FASE 2: DATA UNDERSTANDING
    - Paso 2.1: Setup Inicial
    - Paso 2.2: Carga del Dataset
    - Paso 2.3: Inspecci√≥n Inicial del Dataset
    - Paso 2.4: An√°lisis de Tipos de Datos
    - Paso 2.5: An√°lisis de Distribuci√≥n por G√©nero
    - Paso 2.6: Estad√≠sticas de Variables Clave
    - Paso 2.7: Detecci√≥n de Outliers
    - Paso 2.8: Visualizaciones - Distribuciones
    - Paso 2.9: Visualizaciones - Relaciones
    - Paso 2.10: Matriz de Correlaci√≥n
    - Paso 2.11: An√°lisis Comparativo por G√©nero
    - Paso 2.12: S√≠ntesis de Insights
    - Paso 2.13: Identificaci√≥n de Features para Clustering
    - Paso 2.14: Codificaci√≥n de Variables Categ√≥ricas con OneHotEncoder
    - Paso 2.15: Preparaci√≥n del Dataset Final
    - Paso 2.16: Verificaci√≥n de Calidad de Datos
    - Paso 2.17: An√°lisis de Escalas (Pre-Normalizaci√≥n)
- FASE 3: DATA PREPARATION
    - Paso 3.1: Setup para Normalizaci√≥n
    - Paso 3.2: Aplicar los 3 Scalers
    - Paso 3.3: Comparaci√≥n Visual - Boxplots
    - Paso 3.4: Comparaci√≥n de Distribuciones
    - Paso 3.5: An√°lisis Estad√≠stico Post-Scaling
    - Paso 3.6: Test de Impacto en Clustering
    - Paso 3.7: Decisi√≥n Final de Scaler
    - Paso 3.8: PCA - Reducci√≥n de Dimensionalidad (20 min)
    - Paso 3.9: Feature Selection - Alternativas a PCA (25 min)
        - Paso 1: Imports y Setup Feature Selection
        - Paso 2: Setup y Funci√≥n de Evaluaci√≥n
        - Paso 3: Baseline - Todas las Features
        - Paso 4: Forward Selection
        - Paso 5: Backward Elimination
        - Paso 6: Comparaci√≥n Final
        - Paso 7: Visualizaci√≥n Comparativa
        - Paso 8: An√°lisis y Decisi√≥n Final
        - Paso 9: Decisi√≥n para el Pipeline Final
- FASE 4: MODELING
    - Paso 4.1: K-Means Clustering - Encontrando los Grupos (30 min)
- FASE 5: EVALUATION
    - Paso 5.1: An√°lisis de Clusters y Perfiles (25 min)
    - Paso 5.2: An√°lisis Silhouette Detallado
    - Paso 4.3: Identificaci√≥n de Outliers
    - Paso 4.4: An√°lisis de Perfiles de Cliente
- Challenge 1: Algoritmos de Clustering Alternativos
    - A. DBSCAN - Density-Based Clustering
    - B. HDBSCAN - Hierarchical Density-Based Clustering
    - C. Gaussian Mixture Models
    - D. Spectral Clustering & AgglomerativeClustering
- Challenge 2: Recursive Feature Elimination (RFE)
- Challenge 3: Datasets Alternativos
    - A. Iris Dataset - Cl√°sico de ML
    - B. Wine Dataset - An√°lisis de Vinos
    - C. Synthetic Blobs - Datos Controlados
- Challenge 4: Visualizaci√≥n Avanzada
    - A. t-SNE - Visualizaci√≥n No Lineal
    - B. UMAP - Alternativa Moderna a t-SNE
    - C. Heatmap Avanzado de Caracter√≠sticas
- Challenge 5: Comparaci√≥n Masiva de Algoritmos

## Desarrollo

### Fase 1

¬øQu√© problema estamos resolviendo?

El problema central es la falta de segmentaci√≥n clara de clientes, lo cual dificulta tomar decisiones basadas en datos para optimizar la inversi√≥n en marketing y mejorar la experiencia del cliente.

### Fase 2

En esta fase nos enfocamos en comprender los datos del dataset, asegurando su calidad y extrayendo los primeros insights relevantes para el clustering. Las actividades realizadas fueron:

- Inspecci√≥n general de dimensiones, memoria y estructura del dataset.
- An√°lisis descriptivo de las variables clave: Age, Annual Income (k$) y Spending Score (1-100).
- Revisi√≥n de la distribuci√≥n por g√©nero y comparaci√≥n estad√≠stica entre hombres y mujeres.
- Identificaci√≥n de outliers mediante el m√©todo del IQR.
- Visualizaciones de distribuciones, relaciones entre variables y matriz de correlaci√≥n.
- Preparaci√≥n de los datos para clustering: selecci√≥n de features, codificaci√≥n de la variable categ√≥rica Genre con OneHotEncoder, y verificaci√≥n de calidad.
- An√°lisis de escalas para normalizaci√≥n.

¬øExiste correlaci√≥n fuerte entre alguna variable? No, no se observan correlaciones lineales fuertes.  

¬øQu√© variable tiene m√°s outliers? Annual Income.  

¬øLos hombres y mujeres tienen patrones diferentes?

```
Age: Hombres tienen promedio m√°s alto (diferencia: 1.7)
Annual Income (k$): Hombres tienen promedio m√°s alto (diferencia: 3.0)
Spending Score (1-100): Mujeres tienen promedio m√°s alto (diferencia: 3.0)
```

¬øQu√© insight es m√°s relevante para el an√°lisis? La relaci√≥n clave entre Income y Spending Score.  

¬øQu√© 2 variables ser√°n m√°s importantes para clustering? Annual Income y Spending Score. 

¬øQu√© relaci√≥n entre Income y Spending Score observas? Hay clientes con alto ingreso y bajo gasto, y otros con bajo ingreso y alto gasto, en el medio se concentran la mayoria, con ingresos medios y gasto medio.

¬øPuedes imaginar grupos naturales de clientes? alto ingreso/alto gasto, alto ingreso/bajo gasto, bajo ingreso/alto gasto, bajo ingreso/bajo gasto.

¬øPor qu√© necesitamos normalizaci√≥n? Porque Age est√° en rango 18-70, Income en 15-140, y Spending Score en 1-100. Si no normalizamos, el clustering se sesgar√° hacia Income.

¬øQu√© variable tiene el rango m√°s amplio? Annual Income (15‚Äì140).

¬øCu√°l es la distribuci√≥n de g√©nero en el dataset? Equilibrada (50%-50%), t√≠pico de este dataset de clientes de mall.

¬øQu√© variable muestra mayor variabilidad (std)? Annual Income.

¬øLos clientes son j√≥venes o mayores en promedio? J√≥venes-adultos, la media ronda 40 a√±os.

¬øEl income promedio sugiere qu√© clase social? Media, alrededor de 60k anuales.

¬øPor qu√© la normalizaci√≥n ser√° cr√≠tica aca? Porque las escalas distintas distorsionar√≠an la distancia en clustering.

![](../assets/UT1_TA6_1.png)

![](../assets/UT1_TA6_2.png)

![](../assets/UT1_TA6_3.png)

### Fase 3

En esta fase tenemos que preparar los datos para el modelado, con √©nfasis en normalizaci√≥n, reducci√≥n de dimensionalidad y selecci√≥n de caracter√≠sticas.

#### Paso 3.1 y 3.2 ‚Äì Normalizaci√≥n

Partimos de un dataset con escalas muy diferentes:

- Edad: 18 ‚Äì 70
- Ingresos anuales: 15 ‚Äì 137
- Spending Score: 1 ‚Äì 99
- G√©nero: 0 ‚Äì 1

Esto evidenci√≥ la necesidad de aplicar t√©cnicas de escalado. Probamos MinMaxScaler, StandardScaler y RobustScaler.

#### Paso 3.5 y 3.6 ‚Äì An√°lisis estad√≠stico y prueba con clustering

Despues de comparar distribuciones y boxplots, evaluamos cada escalado con el Silhouette Score:

- MinMax: 0.364
- Standard: 0.332
- Robust: 0.298

El ganador fue MinMaxScaler, con mejor separaci√≥n de clusters.

Seleccionar MinMaxScaler como t√©cnica de normalizaci√≥n para el pipeline.

#### Paso 3.8 ‚Äì PCA (Reducci√≥n de dimensionalidad)

Con los datos ya normalizados, aplicamos PCA para analizar la varianza:

```
üéØ DECISI√ìN DE COMPONENTES:
   üìä Para retener 90% varianza: 3 componentes
   üìä Para retener 95% varianza: 4 componentes
   üéØ Para visualizaci√≥n: 2 componentes (86.3% varianza)

PCA aplicado:
   üìä Dimensiones: (200, 5) ‚Üí (200, 2)
   üìà Varianza explicada: 86.3%

üîç INTERPRETACI√ìN DE COMPONENTES:

   PC1 (varianza: 72.6%):
                 Age:   0.029 ‚Üë
     Annual Income (k$):   0.019 ‚Üë
     Spending Score (1-100):  -0.027 ‚Üì
        Genre_Female:  -0.706 ‚Üì
          Genre_Male:   0.706 ‚Üë

   PC2 (varianza: 13.7%):
                 Age:   0.727 ‚Üë
     Annual Income (k$):  -0.026 ‚Üì
     Spending Score (1-100):  -0.685 ‚Üì
        Genre_Female:   0.027 ‚Üë
          Genre_Male:  -0.027 ‚Üì
```

#### Paso 3.9 ‚Äì Feature Selection vs PCA

Se compar√≥ la reducci√≥n de dimensionalidad con PCA contra la selecci√≥n de caracter√≠sticas mediante Forward Selection y Backward Elimination.

Resultados:

- Baseline (todas las features) ‚Üí Silhouette = 0.364
- Forward Selection ‚Üí Features: Spending Score, Genre_Female, Genre_Male ‚Üí Score = 0.573
- Backward Elimination ‚Üí Features: Spending Score, Genre_Female, Genre_Male ‚Üí Score = 0.573
- PCA (2D) ‚Üí Score = 0.686

An√°lisis:

- El mejor m√©todo fue PCA.
- Forward/Backward Selection (ambos coinciden en las mismas tres features) result√≥ competitivo.
- Ambos m√©todos de selecci√≥n superaron claramente el umbral de 0.5, indicando clusters de buena calidad.

![](../assets/UT1_TA6_4.png)

![](../assets/UT1_TA6_5.png)

![](../assets/UT1_TA6_6.png)

![](../assets/UT1_TA6_7.png)

![](../assets/UT1_TA6_8.png)

Mejor scaler seg√∫n silhouette: MinMax

¬øPor qu√© crees que funcion√≥ mejor? Porque escal√≥ todas las features al mismo rango [0,1], evitando que variables con distinto rango dominen el clustering, y fue suficiente para los outliers presentes.

¬øAlg√∫n scaler tuvo problemas obvios? Robust tuvo un silhouette m√°s bajo.

PC1 parece representar: Diferencia de g√©nero y nivel general de ingresos, separando hombres (PC1 positivo) de mujeres (PC1 negativo).

PC2 parece representar: Edad y comportamiento de gasto, con clientes m√°s j√≥venes y con menor spending score en la parte negativa.

Los clusters visibles sugieren: Grupos de clientes segmentados por g√©nero y comportamiento de gasto.

M√©todo con mejor score: PCA (2D) con silhouette = 0.686"

¬øForward y Backward seleccionaron exactamente las mismas features? S√≠

¬øPCA con 2 componentes es competitivo? S√≠, super√≥ tanto forward/backward selection y baseline, mejorando el clustering notablemente.

¬øAlg√∫n m√©todo super√≥ el threshold de 0.5? S√≠, PCA y ambos m√©todos de feature selection (Forward/Backward).

¬øLa reducci√≥n de dimensionalidad mejor√≥ el clustering? S√≠, PCA 2D aument√≥ el silhouette score de 0.364 ‚Üí 0.686, +88.3% vs baseline.

### Fase 4

- Scaler seleccionado: MinMax (mejor silhouette, 0.364).
- Reducci√≥n dimensional (PCA 2D): conserva 86.3% de la varianza y mejora el clustering (silhouette = 0.686).
- Selecci√≥n de features: Forward y Backward coincidieron en ['Spending Score', 'Genre_Female', 'Genre_Male'], silhouette = 0.573.
- K √≥ptimo para K-Means: Se consideraron Elbow (K=6) y Silhouette (K=2), y por contexto de negocio se eligi√≥ K=4.
- Modelo final K-Means: Silhouette = 0.686, Inertia = 3.78, Clusters equilibrados:
  - Cluster 0: 28.5%
  - Cluster 1: 23.5%
  - Cluster 2: 27.5%
  - Cluster 3: 20.5%

- PC1: diferencia de g√©nero e ingresos
- PC2: edad y comportamiento de gasto
- Los clusters reflejan grupos de clientes balanceados para acciones comerciales.

Se logr√≥ una segmentaci√≥n confiable y visualizable, lista para an√°lisis de perfil de clientes y estrategias de negocio.

![](../assets/UT1_TA6_9.png)

### Fase 5

Perfiles de clusters:

- Cluster 0 (57 clientes, 28.5%): Predominantemente mujeres, edad promedio 28.4 a√±os, ingreso anual $59.7k, Spending Score 67.7/100.
- Cluster 1 (47 clientes, 23.5%): Predominantemente hombres, edad promedio 50.1 a√±os, ingreso anual $62.2k, Spending Score 29.6/100.
- Cluster 2 (55 clientes, 27.5%): Predominantemente mujeres, edad promedio 48.1 a√±os, ingreso anual $58.8k, Spending Score 34.8/100.
- Cluster 3 (41 clientes, 20.5%): Predominantemente hombres, edad promedio 28.0 a√±os, ingreso anual $62.3k, Spending Score 70.2/100.

Evaluaci√≥n de calidad:

- Silhouette Score general: 0.686 ‚Üí clusters bien definidos.
- Silhouette por cluster: todos positivos, sin outliers detectados.
- Distribuci√≥n de clientes: equilibrada entre clusters.

Los clusters son claros, diferenciables y consistentes con perfiles demogr√°ficos y financieros, lo que permite generar estrategias de marketing o fidelizaci√≥n segmentadas.

![](../assets/UT1_TA6_10.png)

## Reflexi√≥n

### Metodolog√≠a CRISP-DM

- Fase m√°s desafiante: La fase de Modeling fue la m√°s compleja, principalmente por la selecci√≥n del n√∫mero √≥ptimo de clusters, ya que el Elbow Method y Silhouette Score no coincid√≠an y fue necesario considerar tambi√©n el contexto de negocio.

- Impacto del entendimiento del negocio: Conocer la expectativa de 3-5 segmentos permiti√≥ decidir un K final de 4 clusters, balanceando m√©tricas t√©cnicas y necesidades comerciales.

### Data Preparation

- Scaler m√°s efectivo:La normalizaci√≥n est√°ndar funcion√≥ mejor para equilibrar las variables num√©ricas sin sesgar la distancia usada en K-Means.

- PCA vs Feature Selection: PCA fue m√°s efectivo en este caso para visualizaci√≥n y reducci√≥n dimensional, manteniendo la mayor parte de la varianza mientras simplificaba la interpretaci√≥n.

- Interpretabilidad vs Performance: Se prioriz√≥ un balance, usando PCA para visualizar clusters en 2D y mantener interpretabilidad, sin sacrificar significativamente la precisi√≥n del clustering.

### Clustering

- Coincidencia entre Elbow y Silhouette: No coincidieron, Elbow suger√≠a K=6 y Silhouette K=2-, por lo que se eligi√≥ K=4 considerando contexto de negocio.

- Coincidencia con la intuici√≥n de negocio: S√≠, los clusters reflejan perfiles demogr√°ficos y financieros distintos, alineados con expectativas.

- Qu√© har√≠a diferente: Explorar otros algoritmos de clustering (como DBSCAN o Gaussian Mixture) y probar transformaciones adicionales de features para validar robustez y estabilidad de los clusters.

### Aplicaci√≥n Pr√°ctica

- Presentaci√≥n empresarial: Los resultados se pueden mostrar en dashboard con gr√°ficos de distribuci√≥n por cluster y perfiles de clientes, destacando edad, g√©nero, ingresos y spending score.

- Valor de las segmentaciones: Permiten personalizar campa√±as de marketing, mejorar retenci√≥n y identificar oportunidades de upselling seg√∫n perfiles financieros y de comportamiento.

- Limitaciones: Basado solo en datos cuantitativos del Mall Customer Dataset, no incluye informaci√≥n conductual ni temporal, y los resultados pueden variar con nuevas muestras de clientes o variables adicionales.

## Referencias
https://colab.research.google.com/drive/1hcVoXTav6u_d921n6YgXnaMkjP2VDGO6?usp=sharing
