---
title: "Pr치ctica 5: Validaci칩n y Selecci칩n de Modelos"
date: 2025-09-08
---

# Pr치ctica 5: Validaci칩n y Selecci칩n de Modelos  

## Contexto
En esta pr치ctica vamos a trabajar sobre validaci칩n y selecci칩n de modelos, un paso importante en cualquier pipeline de machine learning.

Nos enfocaremos en c칩mo evitar data leakage, c칩mo usar validaci칩n cruzada para tener buenos resultados, y c칩mo comparar diferentes algoritmos para elegir el m치s adecuado.

## Objetivos
- Aprender a prevenir data leakage usando pipelines.  
- Implementar validaci칩n cruzada.  
- Comparar m칰ltiples modelos.  
- Interpretar m칠tricas de estabilidad y selecci칩n de modelos.  

## Actividades
- Setup Inicial
- Cargar y Explorar Datos de Estudiantes
- Parte 1: Cross-Validation - Validaci칩n Robusta
    - Preparar datos para validaci칩n
- Parte 2: Cross-Validation - Validaci칩n Robusta
    - Implementar Validaci칩n Cruzada
- Parte 3: Comparaci칩n de Modelos - 춰El Torneo!
    - Competencia de M칰ltiples Modelos
- Bonus 1: Optimizaci칩n de Hiperpar치metros
    - GridSearchCV vs RandomizedSearchCV
- Bonus 2: Explicabilidad del Modelo
    - 쯇or qu칠 el modelo toma esas decisiones?

## Desarrollo

### 1. Setup Inicial

```python
!pip install ucimlrepo

# Importar librer칤as que vamos a usar
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Para validaci칩n y selecci칩n de modelos
from sklearn.linear_model import LogisticRegression, RidgeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, cross_val_score, KFold, StratifiedKFold
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
# Para cargar datos desde UCI ML Repository
from ucimlrepo import fetch_ucirepo
from sklearn.metrics import accuracy_score, classification_report

print("Setup completo!")
```

```python
Collecting ucimlrepo
  Downloading ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)
Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2.2.2)
Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2025.8.3)
Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.0.2)
Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)
Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)
Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)
Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)
Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)
Installing collected packages: ucimlrepo
Successfully installed ucimlrepo-0.0.7
Setup completo!
```

### 2. Cargar y Explorar Datos de Estudiantes

```python
# Cargar dataset de estudiantes desde UCI
student_data = fetch_ucirepo(id=697)

# Preparar datos
X = student_data.data.features
y = student_data.data.targets

print("Dataset: Student Dropout and Academic Success")
print(f"Estudiantes: {X.shape[0]}, Caracter칤sticas: {X.shape[1]}")
print(f"Objetivo: Predecir {len(y.columns)} variable(s)")

# Explorar variable objetivo
target_col = y.columns[0]  # Primera columna objetivo
y_series = y[target_col]
print(f"\nVariable objetivo: {target_col}")

# Mapear valores para mejor interpretaci칩n
target_mapping = {'Dropout': 0, 'Enrolled': 1, 'Graduate': 2}
y_mapped = y_series.map(target_mapping)

# Distribuci칩n de clases
print("\nDistribuci칩n de resultados acad칠micos:")
value_counts = y_mapped.value_counts()
for outcome, count in value_counts.items():
    percentage = (count / len(y_mapped)) * 100
    print(f"  {outcome}: {count} estudiantes ({percentage:.1f}%)")

# Ver algunas caracter칤sticas
print(f"\nPrimeras caracter칤sticas:")
print(X.columns.tolist()[:10], "...")

# Estad칤sticas b치sicas
print(f"\nAge at enrollment:")
if 'Age at enrollment' in X.columns:
    age_col = X['Age at enrollment']
    print(f"  Promedio: {age_col.mean():.1f} a침os")
    print(f"  Rango: {age_col.min():.0f}-{age_col.max():.0f} a침os")
```

```
Dataset: Student Dropout and Academic Success
Estudiantes: 4424, Caracter칤sticas: 36
Objetivo: Predecir 1 variable(s)
Variable objetivo: Target
Distribuci칩n de resultados acad칠micos:
  2: 2209 estudiantes (49.9%)
  0: 1421 estudiantes (32.1%)
  1: 794 estudiantes (17.9%)
Primeras caracter칤sticas:
['Marital Status', 'Application mode', 'Application order', 'Course', 'Daytime/evening attendance', 'Previous qualification', 'Previous qualification (grade)', 'Nacionality', "Mother's qualification", "Father's qualification"] ...

Age at enrollment:
  Promedio: 23.3 a침os
  Rango: 17-70 a침os
```

- 쮺u치ntas muestras y caracter칤sticas tiene el dataset? 
    - El dataset tiene 4424 muestras y 37 caracter칤sticas.
- 쯈u칠 tipos de variables incluye?
    - Incluye variables demogr치ficas, acad칠micas y socioecon칩micas.
- 쯃as clases est치n balanceadas o desbalanceadas? 
    - Las clases est치n desbalanceadas (m치s graduados que abandonos o inscriptos).
- 쯈u칠 significan las 3 categor칤as objetivo?
    - Las 3 categor칤as son:
    0: Dropout (abandono)
    1: Enrolled (cursando)
    2: Graduate (graduado).

### 3. Preparar datos para validaci칩n

```python
# Preparar variable objetivo como serie simple
# Convertir strings a n칰meros para sklearn
target_mapping = {0: 'Dropout', 1: 'Enrolled', 2: 'Graduate'}
reverse_mapping = {'Dropout': 0, 'Enrolled': 1, 'Graduate': 2}

# Si y_series contiene strings, convertir a n칰meros
if y_series.dtype == 'object':
    y_target = y_series.map(reverse_mapping)
else:
    y_target = y_series

X_features = X       # Features del dataset

print("Datos preparados para validaci칩n:")
print(f"X shape: {X_features.shape}")
print(f"y shape: {y_target.shape}")
print(f"Clases 칰nicas: {sorted(y_target.unique())}")
print(f"Mapeo: {target_mapping}")
```

```python
Datos preparados para validaci칩n:
X shape: (4424, 36)
y shape: (4424,)
Clases 칰nicas: [np.int64(0), np.int64(1), np.int64(2)]
Mapeo: {0: 'Dropout', 1: 'Enrolled', 2: 'Graduate'}
```

### 4. Implementar Validaci칩n Cruzada

```python
# === VALIDACI칍N CRUZADA PARA ESTABILIDAD ===

print("游댧 VALIDACI칍N CRUZADA: 쯈u칠 tan estable es nuestro modelo?")

# 1. Crear pipeline robusto para usar en CV
pipeline_robust = Pipeline([
    ('scaler', StandardScaler()),
    ('classifier', LogisticRegression(max_iter=1000, random_state=42))
])

print("Pipeline creado para validaci칩n cruzada")

# 2. Crear KFold b치sico
kfold = KFold(n_splits=5, shuffle=True, random_state=42)

# 3. Evaluar con KFold usando cross_val_score
scores_kfold = cross_val_score(
    pipeline_robust, X_features, y_target, cv=kfold, scoring='accuracy'
)

print(f"\nKFOLD RESULTS:")
print(f"   Scores individuales: {scores_kfold}")
print(f"   Media: {scores_kfold.mean():.4f}")
print(f"   Desviaci칩n est치ndar: {scores_kfold.std():.4f}")
print(f"   Resultado: {scores_kfold.mean():.4f} 췀 {scores_kfold.std():.4f}")

# 4. Crear StratifiedKFold (mantiene proporci칩n de clases)
stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# 5. Evaluar con StratifiedKFold
scores_stratified = cross_val_score(
    pipeline_robust, X_features, y_target, cv=stratified_kfold, scoring='accuracy'
)

print(f"\nSTRATIFIED KFOLD RESULTS:")
print(f"   Scores individuales: {scores_stratified}")
print(f"   Media: {scores_stratified.mean():.4f}")
print(f"   Desviaci칩n est치ndar: {scores_stratified.std():.4f}")
print(f"   Resultado: {scores_stratified.mean():.4f} 췀 {scores_stratified.std():.4f}")

# 6. Comparar estabilidad (menor desviaci칩n = m치s estable)
print(f"\nCOMPARACI칍N DE ESTABILIDAD:")
if scores_stratified.std() < scores_kfold.std():
    print("   StratifiedKFold es M츼S ESTABLE (menor variabilidad)")
    mejor_cv = "StratifiedKFold"
else:
    print("   KFold es M츼S ESTABLE (menor variabilidad)")
    mejor_cv = "KFold"

print(f"   Recomendaci칩n: Usar {mejor_cv} para este dataset")

# 7. Visualizar la distribuci칩n de scores
import matplotlib.pyplot as plt
plt.figure(figsize=(10, 6))
plt.boxplot([scores_kfold, scores_stratified], labels=['KFold', 'StratifiedKFold'])
plt.title('Distribuci칩n de Scores - Validaci칩n Cruzada')
plt.ylabel('Accuracy')
plt.grid(True, alpha=0.3)
plt.show()
```

```python
游댧 VALIDACI칍N CRUZADA: 쯈u칠 tan estable es nuestro modelo?
Pipeline creado para validaci칩n cruzada
KFOLD RESULTS:
   Scores individuales: [0.75254237 0.76610169 0.76836158 0.77740113 0.78054299]
   Media: 0.7690
   Desviaci칩n est치ndar: 0.0098
   Resultado: 0.7690 췀 0.0098
STRATIFIED KFOLD RESULTS:
   Scores individuales: [0.76836158 0.76836158 0.76271186 0.75480226 0.75452489]
   Media: 0.7618
   Desviaci칩n est치ndar: 0.0061
   Resultado: 0.7618 췀 0.0061
COMPARACI칍N DE ESTABILIDAD:
   StratifiedKFold es M츼S ESTABLE (menor variabilidad)
   Recomendaci칩n: Usar StratifiedKFold para este dataset
```

![](../assets/UT1_TA5_1.png)

- 쮺u치l m칠todo mantiene la proporci칩n de clases en cada fold?
    - El m칠todo que mantiene la proporci칩n de clases en cada fold es StratifiedKFold.
- 쮺u치l par치metro especifica el tipo de validaci칩n cruzada en cross_val_score?
    - El par치metro que especifica el tipo de validaci칩n cruzada en cross_val_score es cv.

### 5. Competencia de M칰ltiples Modelos

```python
# === COMPETENCIA DE MODELOS ===

print("游끥 TORNEO: 쮺u치l modelo funciona mejor para diagn칩stico m칠dico?")

# 1. Definir candidatos (diferentes algoritmos)
models = {
    'Logistic Regression': Pipeline([
        ('scaler', StandardScaler()),
        ('classifier', LogisticRegression(max_iter=1000, random_state=42))
    ]),

    # 2. Ridge Classifier (regresi칩n log칤stica con regularizaci칩n L2)
    'Ridge Classifier': Pipeline([
        ('scaler', StandardScaler()),
        ('classifier', RidgeClassifier(alpha=1.0, random_state=42))
    ]),

    # 3. Random Forest (ensemble, no necesita escalado)
    'Random Forest': Pipeline([
        ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))
    ])
}

print(f"Modelos en competencia: {list(models.keys())}")

# 4. Evaluar cada modelo con validaci칩n cruzada
print(f"\nEVALUANDO MODELOS CON 5-FOLD CV...")

results = {}
for name, model in models.items():
    print(f"   Evaluando {name}...")

    # Usar StratifiedKFold para mantener balance de clases
    scores = cross_val_score(
        model, X_features, y_target,
        cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),
        scoring='accuracy'
    )

    results[name] = scores

    print(f"   {name}: {scores.mean():.4f} 췀 {scores.std():.4f}")
    print(f"      Scores: {[f'{s:.3f}' for s in scores]}")

# 5. Encontrar el mejor modelo
print(f"\nRESULTADOS FINALES:")

# Encontrar modelo con mayor accuracy promedio
best_mean_score = 0
best_model_name = ""

for name, scores in results.items():
    if scores.mean() > best_mean_score:
        best_mean_score = scores.mean()
        best_model_name = name

print(f"GANADOR: {best_model_name}")
print(f"Score: {best_mean_score:.4f}")

# 6. An치lisis detallado de estabilidad
print(f"\nAN츼LISIS DE ESTABILIDAD:")
for name, scores in results.items():
    stability = scores.std()

    if stability < 0.02:
        status = "MUY ESTABLE"
    elif stability < 0.05:
        status = "ESTABLE"
    else:
        status = "INESTABLE"

    print(f"   {name}: {status} (std: {stability:.4f})")

# 7. Visualizaci칩n comparativa
plt.figure(figsize=(12, 6))

# Boxplot de distribuci칩n de scores
plt.subplot(1, 2, 1)
plt.boxplot([results[name] for name in models.keys()], 
           labels=[name.split()[0] for name in models.keys()])
plt.title('Distribuci칩n de Accuracy por Modelo')
plt.ylabel('Accuracy')
plt.grid(True, alpha=0.3)

# Barplot de medias con error bars
plt.subplot(1, 2, 2)
names = list(models.keys())
means = [results[name].mean() for name in names]
stds = [results[name].std() for name in names]

plt.bar(range(len(names)), means, yerr=stds, capsize=5)
plt.xticks(range(len(names)), [name.split()[0] for name in names])
plt.title('Accuracy Promedio 췀 Desviaci칩n Est치ndar')
plt.ylabel('Accuracy')
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
```

```python
游끥 TORNEO: 쮺u치l modelo funciona mejor para diagn칩stico m칠dico?
Modelos en competencia: ['Logistic Regression', 'Ridge Classifier', 'Random Forest']

EVALUANDO MODELOS CON 5-FOLD CV...
   Evaluando Logistic Regression...
   Logistic Regression: 0.7618 췀 0.0061
      Scores: ['0.768', '0.768', '0.763', '0.755', '0.755']
   Evaluando Ridge Classifier...
   Ridge Classifier: 0.7509 췀 0.0032
      Scores: ['0.755', '0.746', '0.754', '0.749', '0.751']
   Evaluando Random Forest...
   Random Forest: 0.7658 췀 0.0064
      Scores: ['0.775', '0.764', '0.771', '0.763', '0.757']
      
RESULTADOS FINALES:
GANADOR: Random Forest
Score: 0.7658

AN츼LISIS DE ESTABILIDAD:
   Logistic Regression: MUY ESTABLE (std: 0.0061)
   Ridge Classifier: MUY ESTABLE (std: 0.0032)
   Random Forest: MUY ESTABLE (std: 0.0064)
```

![](../assets/UT1_TA5_2.png)

- Random Forest no necesita escalado, 쯣or qu칠 no incluir StandardScaler?
    - rs un modelo basado en 치rboles de decisi칩n, y estos no se ven afectados por la escala de las variables.
- 쮺u치l m칠trica es mejor para clasificaci칩n: 'accuracy', 'precision', o 'f1'?
    - Accuracy es 칰til si las clases est치n balanceadas. Precision prioriza evitar falsos positivos. F1 tiene un balance entre precision y recall.

#### 쯈u칠 significan las m칠tricas de validaci칩n?

- Cross-Validation: T칠cnica que divide los datos en k partes para entrenar y evaluar m칰ltiples veces.
- Accuracy promedio: La estimaci칩n de rendimiento esperado en datos nuevos.
- Desviaci칩n est치ndar: Indica qu칠 tan estable es el modelo entre diferentes divisiones de datos.
- StratifiedKFold: Mantiene la proporci칩n de clases en cada fold, especialmente importante en datasets desbalanceados.

### 6. GridSearchCV vs RandomizedSearchCV

```python
from sklearn.model_selection import GridSearchCV, RandomizedSearchCV

# Seleccionar el mejor modelo de la competencia anterior
best_model_base = models[best_model_name]

print(f"Optimizando hiperpar치metros para: {best_model_name}")

# Definir espacio de b칰squeda de hiperpar치metros
if 'Random Forest' in best_model_name:
    param_grid = {
        'classifier__n_estimators': [50, 100, 200],
        'classifier__max_depth': [None, 10, 20, 30],
        'classifier__min_samples_split': [2, 5, 10]
    }
elif 'Logistic' in best_model_name:
    param_grid = {
        'classifier__C': [0.1, 1, 10, 100],
        'classifier__max_iter': [1000, 2000]
    }
else:  # Ridge
    param_grid = {
        'classifier__alpha': [0.1, 1, 10, 100]
    }

# M칄TODO 1: GridSearchCV (b칰squeda exhaustiva)
print("\nM칠todo 1: GridSearchCV (b칰squeda exhaustiva)")
grid_search = GridSearchCV(
    best_model_base,
    param_grid,
    cv=5,
    scoring='accuracy',
    n_jobs=-1,
    verbose=1
)

grid_search.fit(X_features, y_target)

print(f"Mejores par치metros (Grid): {grid_search.best_params_}")
print(f"Mejor score (Grid): {grid_search.best_score_:.4f}")

# M칄TODO 2: RandomizedSearchCV (b칰squeda aleatoria, m치s eficiente)
print("\nM칠todo 2: RandomizedSearchCV (b칰squeda aleatoria)")
random_search = RandomizedSearchCV(
    best_model_base,
    param_grid,
    n_iter=20,  # Solo 20 combinaciones aleatorias
    cv=5,
    scoring='accuracy',
    n_jobs=-1,
    random_state=42,
    verbose=1
)

random_search.fit(X_features, y_target)

print(f"Mejores par치metros (Random): {random_search.best_params_}")
print(f"Mejor score (Random): {random_search.best_score_:.4f}")

# Comparar eficiencia
print(f"\nComparaci칩n de eficiencia:")
print(f"GridSearch prob칩: {len(grid_search.cv_results_['params'])} combinaciones")
print(f"RandomSearch prob칩: {len(random_search.cv_results_['params'])} combinaciones")

# Evaluar modelo final optimizado
final_model = grid_search.best_estimator_
final_scores = cross_val_score(final_model, X_features, y_target, cv=5)
print(f"\nModelo final optimizado: {final_scores.mean():.4f} 췀 {final_scores.std():.4f}")
```

```python
Optimizando hiperpar치metros para: Random Forest

M칠todo 1: GridSearchCV (b칰squeda exhaustiva)
Fitting 5 folds for each of 36 candidates, totalling 180 fits
Mejores par치metros (Grid): {'classifier__max_depth': None, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 100}
Mejor score (Grid): 0.7783

M칠todo 2: RandomizedSearchCV (b칰squeda aleatoria)
Fitting 5 folds for each of 20 candidates, totalling 100 fits
Mejores par치metros (Random): {'classifier__n_estimators': 100, 'classifier__min_samples_split': 5, 'classifier__max_depth': 30}
Mejor score (Random): 0.7783

Comparaci칩n de eficiencia:
GridSearch prob칩: 36 combinaciones
RandomSearch prob칩: 20 combinaciones

Modelo final optimizado: 0.7783 췀 0.0067
```

#### 쮺u치ndo usar cada m칠todo?
- GridSearchCV cuando tienes pocos hiperpar치metros y suficiente tiempo de c칩mputo.
- RandomizedSearchCV cuando tienes muchos hiperpar치metros o poco tiempo limitado.
- Pipeline + SearchCV siempre previene data leakage autom치ticamente.
- cross_val_score en el resultado final valida que la optimizaci칩n no caus칩 overfitting.

### 7. 쯇or qu칠 el modelo toma esas decisiones?

```python
# Usar Random Forest para explicabilidad (si no gan칩, crearlo)
if 'Random Forest' not in best_model_name:
    # Crear Random Forest espec칤fico para explicabilidad
    # Random Forest no necesita escalado, as칤 que lo omitimos para simplicidad
    rf_model = Pipeline([
        ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))
    ])
    rf_model.fit(X_features, y_target)
    print("Creado Random Forest espec칤fico para an치lisis de explicabilidad")
else:
    rf_model = final_model
    print("Usando el modelo ganador para explicabilidad")

# Verificar estructura del pipeline
print(f"Componentes del pipeline: {list(rf_model.named_steps.keys())}")

# 1. FEATURE IMPORTANCE - 쯈u칠 caracter칤sticas son m치s importantes?
feature_names = X_features.columns
importances = rf_model.named_steps['classifier'].feature_importances_

# Crear DataFrame para mejor visualizaci칩n
feature_importance_df = pd.DataFrame({
    'feature': feature_names,
    'importance': importances
}).sort_values('importance', ascending=False)

print("\nTOP 10 CARACTER칈STICAS M츼S IMPORTANTES:")
for i, row in feature_importance_df.head(10).iterrows():
    print(f"{row['feature']}: {row['importance']:.4f}")

# Visualizar importancia de caracter칤sticas
plt.figure(figsize=(10, 8))
top_features = feature_importance_df.head(15)
plt.barh(range(len(top_features)), top_features['importance'])
plt.yticks(range(len(top_features)), top_features['feature'])
plt.xlabel('Importancia')
plt.title('Top 15 Caracter칤sticas M치s Importantes para Predecir 칄xito Estudiantil')
plt.gca().invert_yaxis()
plt.tight_layout()
plt.show()

# 2. AN츼LISIS POR CATEGOR칈AS - Agrupar caracter칤sticas relacionadas
academic_features = [col for col in feature_names if any(word in col.lower() 
                    for word in ['grade', 'units', 'curricular', 'semester'])]
demographic_features = [col for col in feature_names if any(word in col.lower() 
                       for word in ['age', 'gender', 'nationality', 'marital'])]
economic_features = [col for col in feature_names if any(word in col.lower() 
                    for word in ['scholarship', 'debt', 'fee', 'tuition'])]

def calculate_category_importance(features, importance_df):
    if not features:
        return 0
    category_importance = importance_df[importance_df['feature'].isin(features)]['importance'].sum()
    return category_importance

academic_importance = calculate_category_importance(academic_features, feature_importance_df)
demographic_importance = calculate_category_importance(demographic_features, feature_importance_df)
economic_importance = calculate_category_importance(economic_features, feature_importance_df)

print(f"\nIMPORTANCIA POR CATEGOR칈AS:")
print(f"Factores acad칠micos: {academic_importance:.4f}")
print(f"Factores demogr치ficos: {demographic_importance:.4f}")
print(f"Factores econ칩micos: {economic_importance:.4f}")

# 3. INTERPRETACI칍N PR츼CTICA - 쯈u칠 significa esto?
print(f"\nINTERPRETACI칍N PARA INTERVENCIONES:")
print(f"La caracter칤stica m치s importante es: {feature_importance_df.iloc[0]['feature']}")
print(f"Esto sugiere que para reducir abandono estudiantil debemos enfocarnos en:")

# Generar recomendaciones basadas en las top features
top_3_features = feature_importance_df.head(3)['feature'].tolist()
for i, feature in enumerate(top_3_features, 1):
    print(f"{i}. Monitorear y mejorar: {feature}")

# 4. PREDICCI칍N INDIVIDUAL - 쯇or qu칠 un estudiante espec칤fico est치 en riesgo?
print(f"\nAN츼LISIS DE ESTUDIANTE INDIVIDUAL (ejemplo):")
student_idx = 0
student_data = X_features.iloc[student_idx:student_idx+1]
prediction = rf_model.predict(student_data)[0]
prediction_proba = rf_model.predict_proba(student_data)[0]

# Definir mapeo localmente para esta secci칩n
outcome_mapping = {0: 'Dropout', 1: 'Enrolled', 2: 'Graduate'}

# Manejar si prediction es string o n칰mero
if isinstance(prediction, str):
    predicted_outcome = prediction
else:
    predicted_outcome = outcome_mapping[prediction]

print(f"Estudiante #{student_idx}:")
print(f"Predicci칩n: {predicted_outcome}")
print(f"Probabilidades:")
for i, prob in enumerate(prediction_proba):
    outcome_name = outcome_mapping[i]
    print(f"  {outcome_name}: {prob:.3f}")

# Mostrar las caracter칤sticas m치s importantes de este estudiante
student_features = pd.DataFrame({
    'feature': feature_names,
    'value': student_data.iloc[0].values,
    'importance': importances
}).sort_values('importance', ascending=False)

print(f"\nTop 5 caracter칤sticas que influyen en esta predicci칩n:")
for i, row in student_features.head(5).iterrows():
    print(f"{row['feature']}: {row['value']:.2f} (importancia: {row['importance']:.4f})")

# 5. VISUALIZACI칍N DE 츼RBOLES INDIVIDUALES
print(f"\nVISUALIZACI칍N DE 츼RBOLES DEL RANDOM FOREST:")

# Instalar graphviz si no est치 disponible
try:
    from sklearn.tree import export_graphviz, plot_tree, export_text
    import matplotlib.pyplot as plt

    # Obtener algunos 치rboles del bosque
    forest = rf_model.named_steps['classifier']
    n_trees_to_show = min(3, len(forest.estimators_))

    print(f"Mostrando {n_trees_to_show} 치rboles de {len(forest.estimators_)} totales")

    # Visualizar 치rboles con plot_tree (m치s simple)
    fig, axes = plt.subplots(1, n_trees_to_show, figsize=(25, 12))
    if n_trees_to_show == 1:
        axes = [axes]

    for i in range(n_trees_to_show):
        tree = forest.estimators_[i]

        # Limitar profundidad para que sea legible
        plot_tree(tree, 
                 ax=axes[i],
                 feature_names=list(feature_names),  # Usar todos los nombres de caracter칤sticas
                 class_names=list(outcome_mapping.values()),
                 filled=True,
                 max_depth=3,  # Limitar profundidad
                 fontsize=6)  # Fuente m치s peque침a para que quepa

        axes[i].set_title(f'츼rbol {i+1} (profundidad m치x: 3)', fontsize=12)

    plt.tight_layout()
    plt.show()

    # Informaci칩n sobre la estructura de los 치rboles
    print(f"\nESTAD칈STICAS DE LOS 츼RBOLES:")
    depths = [tree.get_depth() for tree in forest.estimators_[:5]]
    n_nodes = [tree.tree_.node_count for tree in forest.estimators_[:5]]

    print(f"Profundidad promedio (primeros 5 치rboles): {sum(depths)/len(depths):.1f}")
    print(f"N칰mero promedio de nodos (primeros 5): {sum(n_nodes)/len(n_nodes):.1f}")

    # Mostrar un 치rbol muy simple por texto
    print(f"\nEJEMPLO DE REGLAS DE DECISI칍N (츼rbol 1, simplificado):")
    tree_rules = export_text(forest.estimators_[0], 
                           feature_names=list(feature_names),
                           max_depth=2)
    print(tree_rules[:500] + "..." if len(tree_rules) > 500 else tree_rules)

except ImportError:
    print("Para visualizar 치rboles, instala: pip install graphviz")
    print("Alternativamente, mostramos la estructura del bosque:")

    forest = rf_model.named_steps['classifier']
    print(f"Random Forest contiene {len(forest.estimators_)} 치rboles")
    print(f"Cada 치rbol fue entrenado con {forest.max_features_} caracter칤sticas aleatorias")

    # Estad칤sticas b치sicas sin visualizaci칩n
    if len(forest.estimators_) > 0:
        depths = [tree.get_depth() for tree in forest.estimators_[:5]]
        print(f"Profundidad promedio: {sum(depths)/len(depths):.1f}")

# 6. DIVERSIDAD DEL BOSQUE
print(f"\nDIVERSIDAD EN EL RANDOM FOREST:")
print("El poder del Random Forest viene de la diversidad de sus 치rboles:")
print("- Cada 치rbol ve una muestra diferente de datos (bootstrap)")
print("- Cada split considera solo un subconjunto aleatorio de caracter칤sticas")
print("- La predicci칩n final es el voto mayoritario de todos los 치rboles")

# Mostrar diferencias en predicciones individuales
student_sample = X_features.iloc[0:1]
individual_predictions = []

# Preparar datos dependiendo de si el modelo tiene scaler o no
if 'scaler' in rf_model.named_steps:
    # Modelo con scaler
    scaled_sample = rf_model.named_steps['scaler'].transform(student_sample)
    print("Usando datos escalados para 치rboles individuales")
else:
    # Modelo sin scaler (ej: Random Forest sin preprocesamiento)
    scaled_sample = student_sample.values
    print("Usando datos sin escalar para 치rboles individuales")

for i, tree in enumerate(forest.estimators_[:5]):
    tree_pred = tree.predict(scaled_sample)[0]
    individual_predictions.append(tree_pred)

print(f"\nPredicciones de 치rboles individuales para el Estudiante #0:")
for i, pred in enumerate(individual_predictions):
    pred_name = outcome_mapping[pred] if isinstance(pred, int) else pred
    print(f"  츼rbol {i+1}: {pred_name}")

final_pred = max(set(individual_predictions), key=individual_predictions.count)
final_pred_name = outcome_mapping[final_pred] if isinstance(final_pred, int) else final_pred
print(f"Predicci칩n final (voto mayoritario): {final_pred_name}")
```

```python
Usando el modelo ganador para explicabilidad
Componentes del pipeline: ['classifier']

TOP 10 CARACTER칈STICAS M츼S IMPORTANTES:
Curricular units 2nd sem (approved): 0.1516
Curricular units 2nd sem (grade): 0.1193
Curricular units 1st sem (approved): 0.0987
Curricular units 1st sem (grade): 0.0589
Tuition fees up to date: 0.0466
Curricular units 2nd sem (evaluations): 0.0419
Admission grade: 0.0385
Age at enrollment: 0.0372
Curricular units 1st sem (evaluations): 0.0349
Previous qualification (grade): 0.0343
```

![](../assets/UT1_TA5_3.png)

```python
IMPORTANCIA POR CATEGOR칈AS:
Factores acad칠micos: 0.6443
Factores demogr치ficos: 0.0499
Factores econ칩micos: 0.0769

INTERPRETACI칍N PARA INTERVENCIONES:
La caracter칤stica m치s importante es: Curricular units 2nd sem (approved)
Esto sugiere que para reducir abandono estudiantil debemos enfocarnos en:
1. Monitorear y mejorar: Curricular units 2nd sem (approved)
2. Monitorear y mejorar: Curricular units 2nd sem (grade)
3. Monitorear y mejorar: Curricular units 1st sem (approved)

AN츼LISIS DE ESTUDIANTE INDIVIDUAL (ejemplo):
Estudiante #0:
Predicci칩n: Dropout
Probabilidades:
  Dropout: 0.737
  Enrolled: 0.082
  Graduate: 0.181

Top 5 caracter칤sticas que influyen en esta predicci칩n:
Curricular units 2nd sem (approved): 0.00 (importancia: 0.1516)
Curricular units 2nd sem (grade): 0.00 (importancia: 0.1193)
Curricular units 1st sem (approved): 0.00 (importancia: 0.0987)
Curricular units 1st sem (grade): 0.00 (importancia: 0.0589)
Tuition fees up to date: 1.00 (importancia: 0.0466)

VISUALIZACI칍N DE 츼RBOLES DEL RANDOM FOREST:
Mostrando 3 치rboles de 100 totales

ESTAD칈STICAS DE LOS 츼RBOLES:
Profundidad promedio (primeros 5 치rboles): 21.2
N칰mero promedio de nodos (primeros 5): 1139.0

EJEMPLO DE REGLAS DE DECISI칍N (츼rbol 1, simplificado):
|--- Curricular units 2nd sem (approved) <= 3.50
|   |--- Curricular units 2nd sem (evaluations) <= 7.50
|   |   |--- Curricular units 1st sem (enrolled) <= 0.50
|   |   |   |--- truncated branch of depth 10
|   |   |--- Curricular units 1st sem (enrolled) >  0.50
|   |   |   |--- truncated branch of depth 10
|   |--- Curricular units 2nd sem (evaluations) >  7.50
|   |   |--- Age at enrollment <= 25.50
|   |   |   |--- truncated branch of depth 16
|   |   |--- Age at enrollment >  25.50
|   |  ...
```

![](../assets/UT1_TA5_4.png)

```python
DIVERSIDAD EN EL RANDOM FOREST:
El poder del Random Forest viene de la diversidad de sus 치rboles:
- Cada 치rbol ve una muestra diferente de datos (bootstrap)
- Cada split considera solo un subconjunto aleatorio de caracter칤sticas
- La predicci칩n final es el voto mayoritario de todos los 치rboles
Usando datos sin escalar para 치rboles individuales

Predicciones de 치rboles individuales para el Estudiante #0:
  츼rbol 1: 2.0
  츼rbol 2: 0.0
  츼rbol 3: 0.0
  츼rbol 4: 0.0
  츼rbol 5: 0.0
Predicci칩n final (voto mayoritario): 0.0
```

#### 쯇or qu칠 es importante la explicabilidad?
- Confianza: Los educadores necesitan entender por qu칠 el modelo predice abandono.
- Intervenciones: Knowing las caracter칤sticas importantes permite crear estrategias educativas espec칤ficas.
- Bias detection: La explicabilidad ayuda a detectar sesgos en el modelo.
- Regulaciones: Muchos contextos requieren modelos interpretables por ley.
- Mejora continua: Entender el modelo ayuda a optimizar futuras versiones.

### Preguntas de Reflexi칩n

1. 쯈u칠 es data leakage y por qu칠 es peligroso?
Es cuando el modelo tiene acceso a informaci칩n del futuro o del test durante el entrenamiento. Genera m칠tricas irreales y el modelo falla en datos reales.

2. 쮺u치ndo usar KFold vs StratifiedKFold?
Usa KFold con datasets balanceados. Usa StratifiedKFold cuando hay clases desbalanceadas, porque mantiene la proporci칩n en cada fold.

3. 쮺칩mo interpretar "95.2% 췀 2.1%" en cross-validation?
95.2% = rendimiento promedio esperado. 췀 2.1% = variabilidad entre folds (qu칠 tan estable es el modelo).

4. 쯇or qu칠 Random Forest no necesita StandardScaler?
Porque est치 basado en 치rboles de decisi칩n, que dividen datos por umbrales, no por distancias. La escala de las variables no afecta.

5. En diagn칩stico m칠dico, 쯣refieres 98% accuracy pero inestable, o 95% accuracy muy estable?
Prefiero el 95% estable, porque en medicina la confiabilidad y consistencia son m치s importantes que un pico de rendimiento.

## Reflexi칩n
La validaci칩n y selecci칩n de modelos son pasos importantes para construir sistemas confiables. No alcanza con obtener un modelo con alto accuracy, necesitamos que sea estable, explicable y reproducible. Adem치s, la explicabilidad no solo mejora la confianza en el modelo, sino que tambi칠n permite detectar sesgos y dise침ar mejores estrategias de intervenci칩n.

## Referencias

- Dataset: https://archive.ics.uci.edu/dataset/697/student+dropout+and+academic+success
- Scikit-learn: https://scikit-learn.org/stable/index.html
- Ridge Classifier: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeClassifier.html
- Random Forest: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html
- Cross-validation: https://scikit-learn.org/stable/modules/cross_validation.html
https://colab.research.google.com/drive/1xy7JUUjUr1CrQDYVZdIVBy9xrulPtuKM?usp=sharing