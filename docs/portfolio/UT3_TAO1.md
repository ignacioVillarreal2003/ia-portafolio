---
title: "Cat vs Dogs"
date: 2025-10-31
---

# Cat vs Dogs

## Contexto

Este trabajo aborda la clasificaciÃ³n binaria de imÃ¡genes (gatos vs. perros) con TensorFlow/Keras, poniendo el foco en comparar una red convolucional construida desde cero con un enfoque de Transfer Learning basado en ResNet50. 

El flujo completo incluyÃ³ la preparaciÃ³n del conjunto de datos con `tensorflow_datasets`, la normalizaciÃ³n de imÃ¡genes al rango [0, 1] y el reescalado a 224Ã—224 pÃ­xeles, la definiciÃ³n de arquitecturas, la configuraciÃ³n de entrenamiento con callbacks para regularizaciÃ³n dinÃ¡mica y, finalmente, la evaluaciÃ³n cuantitativa y cualitativa.

## Objetivos

El objetivo principal fue alcanzar un desempeÃ±o de referencia en test igual o superior al 70% de exactitud y, en paralelo, comparar una CNN desde cero frente a un modelo con aprendizaje por transferencia. 

AdemÃ¡s, se buscÃ³ analizar mÃ©tricas por clase para entender asimetrÃ­as en el rendimiento entre â€œCatâ€ y â€œDogâ€, y explorar rÃ¡pidamente arquitecturas livianas (p. ej., MobileNetV2 y EfficientNetB0) que pudieran ofrecer mejor relaciÃ³n precisiÃ³n/parÃ¡metros.

## Actividades

- PreparaciÃ³n y preprocesamiento del dataset
- ImplementaciÃ³n CNN simple y compilaciÃ³n
- ImplementaciÃ³n Transfer Learning (ResNet50)
- Entrenamiento con callbacks (ambos modelos)
- EvaluaciÃ³n, grÃ¡ficas y reportes
- Experimentos con arquitecturas livianas

## Desarrollo

La preparaciÃ³n del dataset se realizÃ³ dividiendo aproximadamente 80/20 para entrenamiento y test, y mapeando un preprocesamiento que normaliza y redimensiona las imÃ¡genes. Se limitaron 4,000 ejemplos para entrenamiento y 1,000 para test con el fin de acelerar el entrenamiento, manteniendo un balance razonable entre clases (aprox. 2,048 â€œCatâ€ y 1,952 â€œDogâ€). Se utilizÃ³ codificaciÃ³n one-hot y un tamaÃ±o de lote de 32 imÃ¡genes por iteraciÃ³n.

```python
ğŸ“Š INFORMACIÃ“N DEL DATASET:
   ğŸ“ˆ Entrenamiento: 4000 imÃ¡genes
   ğŸ§ª Test: 1000 imÃ¡genes
   ğŸ“ Dimensiones: (224, 224, 3) (HxWxC)
   ğŸ“‹ Clases: 2 (ClasificaciÃ³n Binaria)
   ğŸ± Cats: 2051
   ğŸ¶ Dogs: 1949
   ğŸ“¦ Batch size: 32
```

![](../assets/UT3_TAO1_1.png)

La primera arquitectura fue una CNN desde cero con cuatro bloques convolucionales y de pooling, normalizaciÃ³n por lotes y activaciones ReLU. Para favorecer la estabilidad y evitar un nÃºmero excesivo de parÃ¡metros, la red reemplaza el `Flatten` por un `GlobalAveragePooling2D`, seguido de capas densas con `Dropout`. Esta configuraciÃ³n suma 423,490 parÃ¡metros y busca un buen equilibrio entre capacidad representacional y regularizaciÃ³n para imÃ¡genes de 224Ã—224.

```python
ğŸ—ï¸ PASO 3: CNN SIMPLE DESDE CERO
============================================================
ğŸ—ï¸ ARQUITECTURA CNN SIMPLE:
Model: "sequential"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)                    â”ƒ Output Shape           â”ƒ       Param # â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ conv2d (Conv2D)                 â”‚ (None, 224, 224, 32)   â”‚           896 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalization             â”‚ (None, 224, 224, 32)   â”‚           128 â”‚
â”‚ (BatchNormalization)            â”‚                        â”‚               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation (Activation)         â”‚ (None, 224, 224, 32)   â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d (MaxPooling2D)    â”‚ (None, 112, 112, 32)   â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_1 (Conv2D)               â”‚ (None, 112, 112, 64)   â”‚        18,496 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalization_1           â”‚ (None, 112, 112, 64)   â”‚           256 â”‚
â”‚ (BatchNormalization)            â”‚                        â”‚               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_1 (Activation)       â”‚ (None, 112, 112, 64)   â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_1 (MaxPooling2D)  â”‚ (None, 56, 56, 64)     â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_2 (Conv2D)               â”‚ (None, 56, 56, 128)    â”‚        73,856 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalization_2           â”‚ (None, 56, 56, 128)    â”‚           512 â”‚
â”‚ (BatchNormalization)            â”‚                        â”‚               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_2 (Activation)       â”‚ (None, 56, 56, 128)    â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_2 (MaxPooling2D)  â”‚ (None, 28, 28, 128)    â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_3 (Conv2D)               â”‚ (None, 28, 28, 256)    â”‚       295,168 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalization_3           â”‚ (None, 28, 28, 256)    â”‚         1,024 â”‚
â”‚ (BatchNormalization)            â”‚                        â”‚               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_3 (Activation)       â”‚ (None, 28, 28, 256)    â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_3 (MaxPooling2D)  â”‚ (None, 14, 14, 256)    â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ global_average_pooling2d        â”‚ (None, 256)            â”‚             0 â”‚
â”‚ (GlobalAveragePooling2D)        â”‚                        â”‚               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout (Dropout)               â”‚ (None, 256)            â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense (Dense)                   â”‚ (None, 128)            â”‚        32,896 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout_1 (Dropout)             â”‚ (None, 128)            â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_1 (Dense)                 â”‚ (None, 2)              â”‚           258 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 423,490 (1.62 MB)
 Trainable params: 422,530 (1.61 MB)
 Non-trainable params: 960 (3.75 KB)
ğŸ”¢ ParÃ¡metros totales: 423,490
```

El segundo enfoque recurriÃ³ a Transfer Learning con ResNet50 pre-entrenada en ImageNet con el feature extractor congelado. Sobre esa base se aÃ±adieron `GlobalAveragePooling2D` y un clasificador con capas densas, `BatchNormalization` y `Dropout`. El modelo tiene 24,146,434 parÃ¡metros, de los cuales 558,210 son entrenables en esta primera fase.

```python
ğŸ¯ PASO 4: TRANSFER LEARNING
============================================================
Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5
94765736/94765736 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 0us/step
ğŸ¯ ARQUITECTURA TRANSFER LEARNING:
Model: "sequential_1"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)                    â”ƒ Output Shape           â”ƒ       Param # â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ resnet50 (Functional)           â”‚ (None, 7, 7, 2048)     â”‚    23,587,712 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ global_average_pooling2d_1      â”‚ (None, 2048)           â”‚             0 â”‚
â”‚ (GlobalAveragePooling2D)        â”‚                        â”‚               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_2 (Dense)                 â”‚ (None, 256)            â”‚       524,544 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalization_4           â”‚ (None, 256)            â”‚         1,024 â”‚
â”‚ (BatchNormalization)            â”‚                        â”‚               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout_2 (Dropout)             â”‚ (None, 256)            â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_3 (Dense)                 â”‚ (None, 128)            â”‚        32,896 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout_3 (Dropout)             â”‚ (None, 128)            â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_4 (Dense)                 â”‚ (None, 2)              â”‚           258 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 24,146,434 (92.11 MB)
 Trainable params: 558,210 (2.13 MB)
 Non-trainable params: 23,588,224 (89.98 MB)
ğŸ”¢ ParÃ¡metros totales: 24,146,434
ğŸ”“ ParÃ¡metros entrenables: 558,210
```

El entrenamiento de ambos modelos uso `Adam` y callbacks de `EarlyStopping` (monitorizando `val_accuracy` con paciencia 3) y `ReduceLROnPlateau` (reducciÃ³n de la tasa de aprendizaje al detectar estancamiento en `val_loss`). En las primeras Ã©pocas, la CNN simple se estabilizÃ³ alrededor de 0.72â€“0.73 de `val_accuracy`, mientras que el modelo con ResNet50, partiendo mÃ¡s bajo (~0.62), progresÃ³ hasta ~0.71 en validaciÃ³n. 

En test, la CNN desde cero alcanzÃ³ 73.30% de exactitud y el modelo con Transfer Learning obtuvo 70.80%, para una diferencia de -2.50 puntos porcentuales a favor del enfoque desde cero. 

```
ğŸ‹ï¸ PASO 5: ENTRENAMIENTO
============================================================

3ï¸âƒ£ Entrenando modelos...
ğŸ—ï¸ ENTRENANDO CNN SIMPLE...
Epoch 1/15
125/125 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 25s 102ms/step - accuracy: 0.5499 - loss: 0.8372 - val_accuracy: 0.4850 - val_loss: 0.8216 - learning_rate: 0.0010
Epoch 5/15
125/125 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 10s 77ms/step - accuracy: 0.6502 - loss: 0.6175 - val_accuracy: 0.6660 - val_loss: 0.6063 - learning_rate: 0.0010
Epoch 10/15
125/125 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 10s 78ms/step - accuracy: 0.7195 - loss: 0.5535 - val_accuracy: 0.7050 - val_loss: 0.5735 - learning_rate: 2.0000e-04
Epoch 13/15
125/125 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 10s 77ms/step - accuracy: 0.7356 - loss: 0.5373 - val_accuracy: 0.7040 - val_loss: 0.5707 - learning_rate: 1.0000e-04

ğŸ¯ ENTRENANDO TRANSFER LEARNING...
Epoch 1/15
125/125 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 35s 172ms/step - accuracy: 0.5959 - loss: 0.7733 - val_accuracy: 0.5160 - val_loss: 0.6941 - learning_rate: 0.0010
Epoch 5/15
125/125 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 13s 102ms/step - accuracy: 0.7017 - loss: 0.5833 - val_accuracy: 0.6470 - val_loss: 0.6293 - learning_rate: 0.0010
```

El anÃ¡lisis por clase mostrÃ³ que la CNN simple presentÃ³ mejor recall para â€œCatâ€ (0.82) a costa de un menor recall para â€œDogâ€ (0.65), mientras que el Transfer Learning invirtiÃ³ esa tendencia (recall â€œDogâ€ 0.82 y â€œCatâ€ 0.59). En tÃ©rminos de precisiÃ³n, la CNN simple favoreciÃ³ â€œDogâ€ (0.79) y el TL favoreciÃ³ â€œCatâ€ (0.76). 

```python
4ï¸âƒ£ Evaluando modelos...

ğŸ“Š PASO 6: EVALUACIÃ“N Y COMPARACIÃ“N
============================================================
ğŸ“Š COMPARACIÃ“N FINAL:
ğŸ—ï¸ CNN Simple: 0.7050 (70.50%)
ğŸ¯ Transfer Learning: 0.6790 (67.90%)
ğŸ“ˆ Mejora: -2.60%
```

![](../assets/UT3_TAO1_2.png)

```python
ğŸ“‹ REPORTE DE CLASIFICACIÃ“N - CNN SIMPLE:
              precision    recall  f1-score   support

         Cat       0.65      0.87      0.74       485
         Dog       0.81      0.55      0.66       515

    accuracy                           0.70      1000
   macro avg       0.73      0.71      0.70      1000
weighted avg       0.73      0.70      0.70      1000


ğŸ“‹ REPORTE DE CLASIFICACIÃ“N - TRANSFER LEARNING:
              precision    recall  f1-score   support

         Cat       0.64      0.79      0.70       485
         Dog       0.74      0.57      0.65       515

    accuracy                           0.68      1000
   macro avg       0.69      0.68      0.68      1000
weighted avg       0.69      0.68      0.68      1000
```

![](../assets/UT3_TAO1_3.png)

AdemÃ¡s, se ejecutÃ³ un experimento breve con arquitecturas livianas. En pocas Ã©pocas, MobileNetV2 obtuvo 98.70% de exactitud (â‰ˆ2.62M de parÃ¡metros), superando claramente a EfficientNetB0 (48.90%, â‰ˆ4.41M) y a la propia ResNet50 en este rÃ©gimen de entrenamiento corto (51.50%). Dado lo atÃ­pico del 98.70% en un escenario acelerado, este resultado deberÃ­a validarse con mÃºltiples semillas, mayor nÃºmero de Ã©pocas y controles estrictos para descartar cualquier fuga de informaciÃ³n o efectos de sobreajuste inadvertido.

```python
7ï¸âƒ£ Ejecutando experimento adicional...

ğŸ”¬ EXPERIMENTO: 3 ARQUITECTURAS LIVIANAS
============================================================
âœ… EfficientNetB0 disponible - agregado al experimento
ğŸš€ Probando 3 arquitecturas livianas (ejecuciÃ³n rÃ¡pida):
   â€¢ MobileNetV2
   â€¢ ResNet50
   â€¢ EfficientNetB0

ğŸš€ Entrenando MobileNetV2...
Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5
9406464/9406464 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 0us/step
   âœ… MobileNetV2: 0.9840 (98.40%)

ğŸš€ Entrenando ResNet50...
   âœ… ResNet50: 0.5670 (56.70%)

ğŸš€ Entrenando EfficientNetB0...
Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5
16705208/16705208 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 0us/step
   âœ… EfficientNetB0: 0.5150 (51.50%)

ğŸ“Š RESUMEN DE COMPARACIÃ“N:
--------------------------------------------------
ğŸ† MobileNetV2 : 0.9840 (98.40%) - 2,620,098 parÃ¡metros
ğŸ† ResNet50    : 0.5670 (56.70%) - 24,146,434 parÃ¡metros
ğŸ† EfficientNetB0: 0.5150 (51.50%) - 4,411,685 parÃ¡metros

ğŸ¥‡ MEJOR MODELO: MobileNetV2 con 98.40% de precisiÃ³n

ğŸ”¬ EXPERIMENTO 4: ANÃLISIS DE ERRORES
============================================================
32/32 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 20ms/step
ğŸ“Š Predicciones incorrectas: 295 de 1000
ğŸ“Š PrecisiÃ³n: 70.50%

ğŸ” TOP 10 CONFUSIONES MÃS COMUNES:
--------------------------------------------------
ğŸ”„ Dog          â†’ Cat         : 230 casos
ğŸ”„ Cat          â†’ Dog         : 65 casos
```

```python
ğŸ“Š RESUMEN FINAL - CATS VS DOGS:
============================================================
ğŸ—ï¸ CNN Simple (Cats vs Dogs): 70.50%
ğŸ¯ Transfer Learning (Cats vs Dogs): 67.90%
ğŸ“ˆ Mejora con Transfer Learning: -2.60%
ğŸ¤” CNN Simple funcionÃ³ mejor (dataset puede ser muy sintÃ©tico)
```

## ReflexiÃ³n

Este ejercicio refuerza que la calidad del preprocesamiento, la elecciÃ³n de arquitectura y la estrategia de entrenamiento inciden de forma decisiva en el desempeÃ±o final. El hecho de que la CNN desde cero superara a ResNet50 congelada sugiere que, para este dataset y bajo estas condiciones, la arquitectura diseÃ±ada resultÃ³ mÃ¡s adecuada que reutilizar representaciones genÃ©ricas sin ajuste fino.

Para mejorar, serÃ­a conveniente introducir una polÃ­tica de data augmentation mÃ¡s agresiva (volteos, rotaciones, jitter de color, recortes aleatorios) que incremente la diversidad del entrenamiento. En el modelo de Transfer Learning, el siguiente paso natural es habilitar fine-tuning parcial descongelando un subconjunto de capas finales de la base con un learning rate reducido. 

## Referencias

https://colab.research.google.com/drive/1qfOTqIPp7WUWTobZki3J1o2PLvgsX1ji?usp=sharing