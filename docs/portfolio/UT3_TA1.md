---
title: "CNNs y Transfer Learning con TensorFlow/Keras"
date: 2025-10-14
---

# CNNs y Transfer Learning sobre CIFAR-10

## Contexto

En este trabajo se aborda la clasificaciÃ³n automÃ¡tica de imÃ¡genes utilizando redes neuronales convolucionales y tÃ©cnicas de Transfer Learning con TensorFlow/Keras.

El objetivo es aplicar conceptos de deep learning al conjunto de datos CIFAR-10, que contiene imÃ¡genes de objetos comunes distribuidas en 10 clases.

Se busca comparar el desempeÃ±o de un modelo CNN construido desde cero con el de un modelo basado en redes preentrenadas para evaluar la mejora que aporta el aprendizaje transferido.

## Objetivos

- Implementar y entrenar una CNN desde cero para clasificaciÃ³n de imÃ¡genes.
- Aplicar Transfer Learning utilizando modelos preentrenados.
- Evaluar y comparar ambos mediante mÃ©tricas y anÃ¡lisis de overfitting.
- Comprender las ventajas y limitaciones del Transfer Learning frente a CNN.

## Actividades
- Paso 1: Setup y ConfiguraciÃ³n
- Paso 2: Preparar Dataset CIFAR-10
- Paso 3: CNN Simple desde Cero
- Paso 4: Transfer Learning con timm
- Paso 5: Entrenamiento
- Paso 6: EvaluaciÃ³n y ComparaciÃ³n

## Desarrollo

### ConfiguraciÃ³n del entorno y preparaciÃ³n del dataset

El dataset empleado fue CIFAR-10, un conjunto de imÃ¡genes a color de 32x32 pÃ­xeles distribuidas en 10 categorÃ­as balanceadas. Se cargaron 50.000 imÃ¡genes para entrenamiento y 10.000 para prueba. Cada imagen fue normalizada. Se estableciÃ³ un tamaÃ±o de batch de 128 para optimizar el entrenamiento.

### ImplementaciÃ³n de la CNN simple

El primer modelo desarrollado fue una red convolucional simple construida desde cero utilizando la API `Sequential` de Keras. La arquitectura propuesta consistiÃ³ en dos bloques convolucionales con filtros de 32 y 64 neuronas respectivamente, cada uno seguido de una activaciÃ³n ReLU y una capa de MaxPooling2D para la reducciÃ³n espacial. Tras el aplanamiento, se agregÃ³ una capa densa intermedia de 512 neuronas y una capa de salida softmax de 10 neuronas, correspondiente a las clases del dataset.

El modelo fue compilado con el optimizador Adam y la funciÃ³n de pÃ©rdida categorical_crossentropy. El nÃºmero total de parÃ¡metros entrenables fue 2.122.186.

```python
ğŸ—ï¸ IMPLEMENTANDO CNN SIMPLE
--------------------------------------------------
Model: "sequential"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)                    â”ƒ Output Shape           â”ƒ       Param # â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ conv2d_2 (Conv2D)               â”‚ (None, 32, 32, 32)     â”‚           896 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_2 (Activation)       â”‚ (None, 32, 32, 32)     â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_2 (MaxPooling2D)  â”‚ (None, 16, 16, 32)     â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_3 (Conv2D)               â”‚ (None, 16, 16, 64)     â”‚        18,496 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_3 (Activation)       â”‚ (None, 16, 16, 64)     â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_3 (MaxPooling2D)  â”‚ (None, 8, 8, 64)       â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ flatten_1 (Flatten)             â”‚ (None, 4096)           â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense (Dense)                   â”‚ (None, 512)            â”‚     2,097,664 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_1 (Dense)                 â”‚ (None, 10)             â”‚         5,130 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 2,122,186 (8.10 MB)
 Trainable params: 2,122,186 (8.10 MB)
 Non-trainable params: 0 (0.00 B)
ğŸ—ï¸ MODELO CNN SIMPLE:
   ğŸ”¢ ParÃ¡metros: 2,122,186
```

El entrenamiento se realizÃ³ durante 10 Ã©pocas, empleando una validaciÃ³n cruzada con el conjunto de test y la tÃ©cnica de Early Stopping para evitar sobreajuste. Los resultados mostraron una mejora progresiva en precisiÃ³n, alcanzando una precisiÃ³n final del 67.63% en el conjunto de validaciÃ³n.

```python
ğŸ—ï¸ ENTRENANDO CNN SIMPLE...
Epoch 1/10
391/391 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 10s 14ms/step - accuracy: 0.3888 - loss: 1.6912 - val_accuracy: 0.5828 - val_loss: 1.1799
Epoch 2/10
391/391 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3s 7ms/step - accuracy: 0.6007 - loss: 1.1374 - val_accuracy: 0.6407 - val_loss: 1.0330
Epoch 3/10
391/391 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3s 7ms/step - accuracy: 0.6658 - loss: 0.9612 - val_accuracy: 0.6722 - val_loss: 0.9543
Epoch 4/10
391/391 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3s 6ms/step - accuracy: 0.7031 - loss: 0.8479 - val_accuracy: 0.6736 - val_loss: 0.9468
Epoch 5/10
391/391 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3s 7ms/step - accuracy: 0.7414 - loss: 0.7414 - val_accuracy: 0.6763 - val_loss: 0.9498
Epoch 6/10
391/391 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3s 7ms/step - accuracy: 0.7764 - loss: 0.6480 - val_accuracy: 0.6712 - val_loss: 1.0127
Epoch 7/10
391/391 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3s 7ms/step - accuracy: 0.8037 - loss: 0.5657 - val_accuracy: 0.6700 - val_loss: 1.0709
Epoch 8/10
391/391 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3s 6ms/step - accuracy: 0.8396 - loss: 0.4757 - val_accuracy: 0.6649 - val_loss: 1.1428
```

Sin embargo, se observÃ³ un gap significativo entre las curvas de entrenamiento y validaciÃ³n, indicando un overfitting moderado, perdiendo capacidad de generalizaciÃ³n.

```python
ğŸ” ANÃLISIS DE OVERFITTING:
ğŸ—ï¸ CNN Simple - Gap Train-Val: 0.169
âš ï¸ CNN Simple muestra overfitting significativo

ğŸ“‹ REPORTE DE CLASIFICACIÃ“N - CNN SIMPLE:
              precision    recall  f1-score   support

    airplane       0.74      0.72      0.73      1000
  automobile       0.79      0.81      0.80      1000
        bird       0.61      0.52      0.56      1000
         cat       0.60      0.35      0.45      1000
        deer       0.53      0.73      0.61      1000
         dog       0.70      0.47      0.56      1000
        frog       0.77      0.75      0.76      1000
       horse       0.62      0.84      0.71      1000
        ship       0.67      0.89      0.77      1000
       truck       0.82      0.68      0.74      1000

    accuracy                           0.68     10000
   macro avg       0.68      0.68      0.67     10000
weighted avg       0.68      0.68      0.67     10000
```

### Transfer Learning con VGG16

Con el fin de mejorar la capacidad de generalizaciÃ³n y aprovechar el conocimiento previo de modelos entrenados sobre conjuntos extensos como ImageNet, se implementÃ³ una estrategia de transferencia de aprendizaje basada en la arquitectura VGG16.

Se cargÃ³ el modelo base de VGG16 sin las capas superiores y con los pesos preentrenados de ImageNet. Inicialmente, se congelaron todas las capas convolucionales para preservar las representaciones visuales previamente aprendidas, y se aÃ±adieron una capa de Flatten y una Dense softmax para la clasificaciÃ³n sobre las 10 clases de CIFAR-10.

```python
ğŸ¯ IMPLEMENTANDO TRANSFER LEARNING
--------------------------------------------------
Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5
58889256/58889256 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 0us/step
Model: "sequential_1"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)                    â”ƒ Output Shape           â”ƒ       Param # â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ vgg16 (Functional)              â”‚ (None, 1, 1, 512)      â”‚    14,714,688 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ flatten_2 (Flatten)             â”‚ (None, 512)            â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_2 (Dense)                 â”‚ (None, 10)             â”‚         5,130 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 14,719,818 (56.15 MB)
 Trainable params: 5,130 (20.04 KB)
 Non-trainable params: 14,714,688 (56.13 MB)
ğŸ¯ MODELO CON TRANSFER LEARNING:
   ğŸ”¢ ParÃ¡metros totales: 14,719,818
   ğŸ”“ ParÃ¡metros entrenables: 5,130
```

Este modelo alcanzÃ³ un total de 14.719.818 parÃ¡metros, de los cuales solo 5.130 fueron entrenables (correspondientes a la nueva capa de clasificaciÃ³n). Tras el entrenamiento, se obtuvo una precisiÃ³n de 57.69%, ligeramente inferior a la CNN simple. Esto evidenciÃ³ que, si bien la red preentrenada contiene representaciones, la diferencia en tamaÃ±o y dominio del dataset (ImageNet â†’ CIFAR-10) requiere un ajuste fino (fine-tuning) para obtener mejores resultados.

```python
ğŸ¯ ENTRENANDO TRANSFER LEARNING...
Epoch 1/10
391/391 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 18s 37ms/step - accuracy: 0.3324 - loss: 1.9245 - val_accuracy: 0.4928 - val_loss: 1.4966
Epoch 2/10
391/391 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 9s 23ms/step - accuracy: 0.5137 - loss: 1.4438 - val_accuracy: 0.5273 - val_loss: 1.3874
Epoch 3/10
391/391 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 9s 24ms/step - accuracy: 0.5427 - loss: 1.3490 - val_accuracy: 0.5425 - val_loss: 1.3358
Epoch 4/10
391/391 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 9s 24ms/step - accuracy: 0.5583 - loss: 1.2991 - val_accuracy: 0.5507 - val_loss: 1.3040
Epoch 5/10
391/391 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 10s 24ms/step - accuracy: 0.5670 - loss: 1.2664 - val_accuracy: 0.5570 - val_loss: 1.2819
Epoch 6/10
391/391 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 9s 24ms/step - accuracy: 0.5745 - loss: 1.2427 - val_accuracy: 0.5645 - val_loss: 1.2655
Epoch 7/10
391/391 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 9s 24ms/step - accuracy: 0.5807 - loss: 1.2245 - val_accuracy: 0.5681 - val_loss: 1.2529
Epoch 8/10
391/391 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 9s 24ms/step - accuracy: 0.5855 - loss: 1.2099 - val_accuracy: 0.5702 - val_loss: 1.2428
Epoch 9/10
391/391 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 10s 24ms/step - accuracy: 0.5907 - loss: 1.1980 - val_accuracy: 0.5734 - val_loss: 1.2346
Epoch 10/10
391/391 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 10s 24ms/step - accuracy: 0.5928 - loss: 1.1880 - val_accuracy: 0.5769 - val_loss: 1.2278
```

El anÃ¡lisis de overfitting mostrÃ³ un gap muy reducido, indicando una excelente capacidad de generalizaciÃ³n, aunque con menor rendimiento absoluto.

```python
ğŸ” ANÃLISIS DE OVERFITTING:
ğŸ¯ Transfer Learning - Gap Train-Val: 0.016

ğŸ“‹ REPORTE DE CLASIFICACIÃ“N - TRANSFER LEARNING:
              precision    recall  f1-score   support

    airplane       0.62      0.66      0.64      1000
  automobile       0.63      0.63      0.63      1000
        bird       0.53      0.43      0.47      1000
         cat       0.42      0.43      0.42      1000
        deer       0.52      0.55      0.53      1000
         dog       0.53      0.51      0.52      1000
        frog       0.65      0.64      0.64      1000
       horse       0.62      0.61      0.61      1000
        ship       0.65      0.70      0.68      1000
       truck       0.59      0.61      0.60      1000

    accuracy                           0.58     10000
   macro avg       0.58      0.58      0.58     10000
weighted avg       0.58      0.58      0.58     10000
```

### EvaluaciÃ³n comparativa

El reporte de clasificaciÃ³n evidenciÃ³ que la CNN simple tuvo un mejor desempeÃ±o general. Por otro lado, el modelo de transfer learning presentÃ³ un rendimiento mÃ¡s equilibrado entre clases, aunque con menor precisiÃ³n global.

El transfer learning sin fine-tuning no supera necesariamente a una CNN bien ajustada desde cero, especialmente cuando el dominio del dataset difiere notablemente del original.

```python
ğŸ“Š EVALUACIÃ“N FINAL
--------------------------------------------------
ğŸ“Š COMPARACIÃ“N FINAL:
ğŸ—ï¸ CNN Simple: 0.6763
ğŸ¯ Transfer Learning: 0.5769
```

![](../assets/UT3_TA1_1.png)

### InvestigaciÃ³n libre y experimentos adicionales

Se realizaron tres pruebas con el objetivo de mejorar el rendimiento y analizar el comportamiento de distintas estrategias de entrenamiento.

Experimento 1 â€“ CNN mejorada:

- Se agregÃ³ Batch Normalization, Dropout y regularizaciÃ³n L2 a la CNN base.
- El modelo alcanzÃ³ una precisiÃ³n de 75.25%, mostrando una mejora notable y un entrenamiento estable sin sobreajuste importante.
- La combinaciÃ³n de normalizaciÃ³n y regularizaciÃ³n optimizÃ³ la generalizaciÃ³n del modelo.

Experimento 2 â€“ Transfer Learning con ResNet50 (congelada):

- Se utilizÃ³ ResNet50 preentrenada en ImageNet, sin ajustar sus capas.
- Obtuvo una precisiÃ³n de 34.91%, evidenciando que las caracterÃ­sticas de ImageNet no se transfieren bien a imÃ¡genes pequeÃ±as como CIFAR-10.
- El modelo no se adaptÃ³ al dominio del dataset.

Experimento 3 â€“ Fine-tuning de ResNet50:

- Se liberaron las Ãºltimas 30 capas y se reentrenÃ³ con una tasa de aprendizaje baja.
- El resultado fue similar (34.25%), sin mejoras significativas frente al modelo congelado.
- El fine-tuning parcial no aportÃ³ beneficios con la configuraciÃ³n usada.

```python
ğŸ“Š RESULTADOS FINALES:
CNN Mejorada             : 75.25%
ResNet50 (Congelada)     : 34.91%
ResNet50 (Fine-tuned)    : 34.25%
```

![](../assets/UT3_TA1_2.png)

---

Se implementÃ³ una CNN mejorada para el dataset CIFAR-10, incorporando capas convolucionales con Batch Normalization, Dropout y regularizaciÃ³n L2 para mejorar la estabilidad del entrenamiento y reducir el sobreajuste. AdemÃ¡s, se aplicÃ³ data augmentation con rotaciones, desplazamientos y flips horizontales, aumentando la diversidad del conjunto de entrenamiento. El modelo se entrenÃ³ durante 50 Ã©pocas con callbacks de EarlyStopping y ReduceLROnPlateau, ajustando automÃ¡ticamente la tasa de aprendizaje segÃºn la evoluciÃ³n de la pÃ©rdida en validaciÃ³n.

El entrenamiento mostrÃ³ un progreso constante, alcanzando un pico de precisiÃ³n en validaciÃ³n superior al 86%, con curvas de entrenamiento y validaciÃ³n cercanas, indicando un buen equilibrio entre aprendizaje y generalizaciÃ³n. Las tÃ©cnicas de regularizaciÃ³n y normalizaciÃ³n permitieron controlar el overfitting y mantener la estabilidad del modelo incluso con un nÃºmero elevado de parÃ¡metros.

```python
âœ… PrecisiÃ³n final en test: 86.64%
```

![](../assets/UT3_TA1_3.png)

## ReflexiÃ³n

El trabajo mostrÃ³ cÃ³mo las redes neuronales convolucionales pueden resolver problemas de clasificaciÃ³n de imÃ¡genes en conjuntos de datos como CIFAR-10. La CNN simple logrÃ³ una precisiÃ³n razonable, pero presentÃ³ un sobreajuste moderado, evidenciado por la diferencia entre precisiÃ³n de entrenamiento y validaciÃ³n.

La CNN mejorada, con Batch Normalization, Dropout y regularizaciÃ³n L2, alcanzÃ³ la mejor precisiÃ³n (75.25%) y mostrÃ³ un entrenamiento mÃ¡s estable, lo que confirma que la optimizaciÃ³n de la arquitectura y la incorporaciÃ³n de estrategias de regularizaciÃ³n pueden mejorar significativamente la generalizaciÃ³n sin depender de modelos preentrenados.

Por otro lado, los modelos de Transfer Learning (VGG16 y ResNet50) no lograron superar a las CNN propias. Esto evidencia que el aprendizaje transferido no garantiza mejores resultados en todos los casos y que, para datasets pequeÃ±os o especÃ­ficos, una CNN bien diseÃ±ada y entrenada desde cero puede ofrecer un equilibrio superior entre rendimiento y capacidad de generalizaciÃ³n.

La CNN mejorada demostrÃ³ un rendimiento notable, superando ampliamente a modelos mÃ¡s simples y evidenciando que la combinaciÃ³n de arquitectura profunda, regularizaciÃ³n y data augmentation es efectiva para conjuntos de datos como CIFAR-10. El modelo alcanzÃ³ un 86.64% de precisiÃ³n en test, mostrando capacidad de generalizaciÃ³n y estabilidad. Esto confirma que, una CNN optimizada desde cero puede superar modelos de Transfer Learning sin fine-tuning, ofreciendo un balance Ã³ptimo entre precisiÃ³n y control del overfitting.

## Referencias

- https://colab.research.google.com/drive/1VoEmxEiYMqO644GJxg58GG5AmHYk33SK?usp=sharing