---
title: "Food-101"
date: 2025-10-31
---

# Food-101

## Contexto

En esta actividad se trabajÃ³ con el dataset Food-101, que contiene imÃ¡genes de 101 diferentes clases de alimentos. El objetivo principal fue implementar tÃ©cnicas para clasificaciÃ³n de imÃ¡genes, incluyendo data augmentation, transfer learning y mÃ©todos de explicabilidad de modelos.

## Objetivos

- Implementar un modelo de clasificaciÃ³n de imÃ¡genes utilizando transfer learning con EfficientNetB0
- Aplicar tÃ©cnicas de data augmentation para mejorar la robustez del modelo
- Implementar y visualizar mÃ©todos de explicabilidad (GradCAM, Integrated Gradients y LIME) para entender las decisiones del modelo

## Actividades

- ConfiguraciÃ³n inicial y carga del dataset Food-101
- ImplementaciÃ³n de pipelines de data augmentation
- CreaciÃ³n y entrenamiento del modelo con transfer learning
- ImplementaciÃ³n de tÃ©cnicas de explicabilidad
- AnÃ¡lisis y visualizaciÃ³n de resultados

## Desarrollo

### ConfiguraciÃ³n Inicial y PreparaciÃ³n del Dataset

Para el manejo de imÃ¡genes, establecimos un tamaÃ±o estÃ¡ndar de 224x224 pÃ­xeles y un tamaÃ±o de batch de 32. El dataset Food-101 se cargÃ³ utilizando TensorFlow Datasets, que contiene un total de 101 clases diferentes de alimentos. Para optimizar el tiempo de desarrollo, trabajamos con un subset del dataset: 20,000 imÃ¡genes para entrenamiento y 5,000 para validaciÃ³n.

```python
Dataset food101 downloaded and prepared to /root/tensorflow_datasets/food101/2.0.0. Subsequent calls will reuse this data.
âœ… Dataset descargado:
   Train: 75750 imÃ¡genes
   Val:   25250 imÃ¡genes
   Clases: 101

âœ… Datasets preparados (resize a 224x224, sin normalizar):
   Train subset: 20000
   Val subset:   5000
   Rango de pÃ­xeles: [0, 255]
```

### ImplementaciÃ³n de Data Augmentation

Se desarrollo dos pipelines diferentes para el procesamiento de datos:

El pipeline baseline se encargÃ³ de:

- Redimensionar las imÃ¡genes a 224x224
- Aplicar normalizaciÃ³n especÃ­fica para EfficientNet
- Mantener las imÃ¡genes en el rango [0, 255] antes de la normalizaciÃ³n

El pipeline aumentado incluyÃ³ transformaciones mÃ¡s sofisticadas:

- Volteos horizontales y verticales aleatorios para aumentar la variabilidad
- Rotaciones de hasta 45 grados
- Zoom aleatorio de hasta 20%
- Traslaciones de hasta 10% en ambas direcciones
- Ajustes de contraste y brillo
- NormalizaciÃ³n final para EfficientNet

Estas transformaciones se visualizaron para verificar su correcta implementaciÃ³n y asegurar que mantenÃ­an la integridad de las imÃ¡genes.

![](../assets/UT3_TAO2_1.png)

### Arquitectura del Modelo y Proceso de Entrenamiento

Se implemento un modelo basado en transfer learning utilizando EfficientNetB0. La arquitectura final consistiÃ³ en:

- EfficientNetB0 pre-entrenado en ImageNet (con pesos congelados)
- Una capa de Global Average Pooling para reducir la dimensionalidad
- Una capa de Dropout con tasa de 0.2 para prevenir el overfitting
- Una capa densa final con 101 neuronas (una por clase) y activaciÃ³n softmax

```python
âœ… Modelo creado
   ParÃ¡metros: 4,178,952
Model: "sequential"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â”ƒ Layer (type)                                        â”ƒ Output Shape                           â”ƒ               Para
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â”‚ efficientnetb0 (Functional)                         â”‚ (None, 7, 7, 1280)                     â”‚             4,049,
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚ global_average_pooling2d (GlobalAveragePooling2D)   â”‚ (None, 1280)                           â”‚                   
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚ dropout (Dropout)                                   â”‚ (None, 1280)                           â”‚                   
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚ dense (Dense)                                       â”‚ (None, 101)                            â”‚               129,
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 Total params: 4,178,952 (15.94 MB)
 Trainable params: 129,381 (505.39 KB)
 Non-trainable params: 4,049,571 (15.45 MB)
```

El modelo se compilÃ³ con:

- Optimizador: Adam
- FunciÃ³n de pÃ©rdida: Sparse Categorical Crossentropy
- MÃ©trica: Accuracy

El entrenamiento se realizÃ³ durante 6 Ã©pocas utilizando el pipeline aumentado para el conjunto de entrenamiento y el pipeline baseline para validaciÃ³n. Los resultados mostraron una mejora progresiva en la precisiÃ³n tanto en entrenamiento como en validaciÃ³n.

```python
ğŸš€ ENTRENANDO MODELO
============================================================
Epoch 1/6
625/625 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 363s 525ms/step - accuracy: 0.2016 - loss: 3.6530 - val_accuracy: 0.5322 - val_loss: 1.9245
Epoch 2/6
625/625 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 317s 502ms/step - accuracy: 0.4258 - loss: 2.3797 - val_accuracy: 0.5734 - val_loss: 1.6416
Epoch 3/6
625/625 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 313s 494ms/step - accuracy: 0.4660 - loss: 2.1685 - val_accuracy: 0.5968 - val_loss: 1.5287
Epoch 4/6
625/625 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 313s 495ms/step - accuracy: 0.4853 - loss: 2.0869 - val_accuracy: 0.6080 - val_loss: 1.4635
Epoch 5/6
625/625 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 312s 492ms/step - accuracy: 0.4930 - loss: 2.0113 - val_accuracy: 0.6162 - val_loss: 1.4122
Epoch 6/6
625/625 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 310s 491ms/step - accuracy: 0.5135 - loss: 1.9408 - val_accuracy: 0.6214 - val_loss: 1.3941

âœ… Entrenamiento completado
   ğŸ“Š Mejor val_accuracy: 62.14%
```

```python
ğŸ“Š RESULTADOS FINALES:
   Val Accuracy: 62.32%
   Val Loss: 1.3910
```

![](../assets/UT3_TAO2_2.png)

### 4. TÃ©cnicas de Explicabilidad

Se implemento tres tÃ©cnicas diferentes de explicabilidad para entender mejor las decisiones del modelo:

1. GradCAM:

Se identifico automÃ¡ticamente la Ãºltima capa convolucional del modelo y generamos mapas de calor que resaltan las regiones mÃ¡s importantes para la predicciÃ³n. Esta tÃ©cnica nos permitiÃ³ visualizar quÃ© partes de la imagen el modelo consideraba mÃ¡s relevantes para su decisiÃ³n.

![](../assets/UT3_TAO2_3.png)

![](../assets/UT3_TAO2_4.png)

2. Integrated Gradients:

Se implemento con 50 pasos de interpolaciÃ³n entre una imagen base (negra) y la imagen de entrada. Esta tÃ©cnica nos proporcionÃ³ una vista mÃ¡s granular de la contribuciÃ³n de cada pÃ­xel a la predicciÃ³n final.

![](../assets/UT3_TAO2_5.png)

![](../assets/UT3_TAO2_6.png)

3. LIME (Local Interpretable Model-agnostic Explanations):

Se configuro LIME para generar explicaciones locales de las predicciones, utilizando 1000 muestras por imagen y visualizando las 10 regiones mÃ¡s importantes que influyen en la clasificaciÃ³n.

![](../assets/UT3_TAO2_7.png)

![](../assets/UT3_TAO2_8.png)

## ReflexiÃ³n

Durante el proceso de implementaciÃ³n, observÃ© cÃ³mo el data augmentation contribuyÃ³ significativamente a la capacidad del modelo para generalizar mejor, especialmente en un dataset tan diverso como Food-101.

Los resultados del entrenamiento mostraron una evoluciÃ³n positiva en la precisiÃ³n del modelo. GradCAM mostrÃ³ que el modelo efectivamente se enfocaba en las caracterÃ­sticas distintivas de cada plato, mientras que Integrated Gradients proporcionÃ³ una visiÃ³n mÃ¡s detallada de cÃ³mo cada regiÃ³n de la imagen contribuÃ­a a la clasificaciÃ³n final.

Las tÃ©cnicas de explicabilidad implementadas no solo ayudaron a entender mejor las decisiones del modelo, sino que tambiÃ©n proporcionaron una base para la confianza en sus predicciones.

## Referencias

- https://colab.research.google.com/drive/1DYzDoEOcwinQ_m1kBIq3n23bkOs-kob_?usp=sharing