---
title: "Assignment UT3-10: Data Augmentation Avanzado & Explicabilidad - Fill in the Blanks"
date: 2025-10-16
---

# Data Augmentation Avanzado de Modelos de ClasificaciÃ³n de Flores

## Contexto

Esta actividad se centra en entrenar y evaluar modelos de clasificaciÃ³n de imÃ¡genes utilizando el dataset Oxford Flowers102. Se busca mejorar la robustez de los modelos mediante tÃ©cnicas avanzadas de data augmentation y proporcionar explicaciones visuales de sus predicciones usando GradCAM e Integrated Gradients. 

El objetivo final es desarrollar un modelo confiable para la identificaciÃ³n de flores, capaz de clasificar 102 especies diferentes bajo condiciones variables de iluminaciÃ³n, Ã¡ngulo y fondo.

## Objetivos

* Implementar pipelines de data augmentation avanzadas para mejorar la generalizaciÃ³n del modelo.
* Evaluar la robustez del modelo ante variaciones en condiciones de captura de imÃ¡genes.
* Aplicar GradCAM para visualizar las regiones de atenciÃ³n del modelo durante la predicciÃ³n.
* Implementar Integrated Gradients para obtener explicaciones detalladas de las predicciones.

## Actividades

- Parte 1: Setup y Carga del Dataset
    - PASO 1: InstalaciÃ³n e Imports
    - PASO 2: Descargar y Preparar Dataset
- Parte 2: Pipelines de Data Augmentation
    - PASO 3: Pipeline Baseline (Sin Augmentation Avanzada)
    - PASO 4: Pipeline con Augmentation Avanzado
    - PASO 5: Visualizar Augmentations
- Parte 3 (OPCIONAL): Explorar Mixup/CutMix
- Parte 4: Entrenar tu Modelo
    - PASO 8: Crear tu Modelo
    - PASO 9: Entrenar el Modelo
    - PASO 10: Evaluar Resultados
- Parte 5: Explicabilidad con GradCAM
    - PASO 11: GradCAM
- Parte 6: Integrated Gradients
    - PASO 12: Integrated Gradients

## Desarrollo

### Carga y preparaciÃ³n del dataset

El dataset utilizado fue Oxford Flowers102, compuesto por 102 clases de flores, con 1020 imÃ¡genes de entrenamiento y 6149 de prueba. Para agilizar los experimentos iniciales se decidiÃ³ trabajar con un subset de 5000 imÃ¡genes de entrenamiento y 1000 de prueba, lo que permitiÃ³ realizar iteraciones rÃ¡pidas sin sacrificar la diversidad de las clases. Todas las imÃ¡genes fueron redimensionadas a 224x224 pÃ­xeles, preparÃ¡ndolas para ser procesadas por los modelos de deep learning.

Se implementaron dos pipelines de datos. El primero, un pipeline baseline, aplicaba shuffle, batching y normalizaciÃ³n usando el preprocesamiento de EfficientNet. El segundo incorporaba data augmentation avanzada, mediante capas de Keras que realizaban transformaciones geomÃ©tricas y fotomÃ©tricas como flips, rotaciones, zoom, traslaciones, brillo y contraste. Se realizaron visualizaciones de las augmentations para confirmar que las transformaciones eran coherentes y aportaban diversidad al conjunto de entrenamiento.

![](../assets/UT3_TA2_1.png)

### DefiniciÃ³n y entrenamiento del modelo

Se eligiÃ³ un enfoque de transfer learning usando ResNet50 preentrenada en ImageNet. La base convolucional se mantuvo congelada inicialmente y se agregÃ³ un clasificador con GlobalAveragePooling2D y una capa densa con activaciÃ³n softmax para las 102 clases. El modelo se compilÃ³ con el optimizador Adam y la funciÃ³n de pÃ©rdida `sparse_categorical_crossentropy`.

El entrenamiento se realizÃ³ durante 10 epochs utilizando el pipeline con augmentations, logrando un accuracy de validaciÃ³n mÃ¡ximo de 52.9%. Estos resultados indicaron que el modelo estaba aprendiendo patrones relevantes a pesar de trabajar con un subset reducido del dataset.

```python
âœ… Modelo creado
   ParÃ¡metros: 23,796,710

ğŸš€ ENTRENANDO MODELO
============================================================
Epoch 1/10
32/32 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 41s 870ms/step - accuracy: 0.0283 - loss: 5.3766 - val_accuracy: 0.1520 - val_loss: 3.8605
Epoch 2/10
32/32 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 18s 485ms/step - accuracy: 0.2008 - loss: 3.4561 - val_accuracy: 0.2790 - val_loss: 3.0985
Epoch 3/10
32/32 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 21s 515ms/step - accuracy: 0.4365 - loss: 2.4720 - val_accuracy: 0.3600 - val_loss: 2.8030
Epoch 4/10
32/32 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 17s 481ms/step - accuracy: 0.5784 - loss: 1.9866 - val_accuracy: 0.4160 - val_loss: 2.5751
Epoch 5/10
32/32 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 21s 486ms/step - accuracy: 0.6320 - loss: 1.7032 - val_accuracy: 0.4230 - val_loss: 2.4790
Epoch 6/10
32/32 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 21s 479ms/step - accuracy: 0.7295 - loss: 1.3317 - val_accuracy: 0.4630 - val_loss: 2.3358
Epoch 7/10
32/32 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 18s 495ms/step - accuracy: 0.7598 - loss: 1.1908 - val_accuracy: 0.4850 - val_loss: 2.3307
Epoch 8/10
32/32 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 21s 490ms/step - accuracy: 0.7708 - loss: 1.0920 - val_accuracy: 0.5050 - val_loss: 2.2712
Epoch 9/10
32/32 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 18s 480ms/step - accuracy: 0.8113 - loss: 0.9344 - val_accuracy: 0.5290 - val_loss: 2.1537
Epoch 10/10
32/32 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 18s 472ms/step - accuracy: 0.8482 - loss: 0.8579 - val_accuracy: 0.5270 - val_loss: 2.0677
WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. 

âœ… Entrenamiento completado
   ğŸ“Š Mejor accuracy: 52.90%

16/16 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3s 157ms/step - accuracy: 0.5247 - loss: 2.0220

ğŸ“Š RESULTADOS FINALES:
   Test Accuracy: 52.70%
   Test Loss: 2.0677
```

![](../assets/UT3_TA2_2.png)

### EvaluaciÃ³n e interpretabilidad

La evaluaciÃ³n final sobre el conjunto de test arrojÃ³ un accuracy de 52.7% y una pÃ©rdida de 2.0677, coherentes con la evoluciÃ³n durante el entrenamiento. Para analizar la interpretabilidad del modelo se implementaron tÃ©cnicas de GradCAM e Integrated Gradients, las cuales permitieron visualizar quÃ© regiones de las imÃ¡genes influyen mÃ¡s en las predicciones. Estas herramientas ayudaron a verificar que el modelo se enfocaba en las Ã¡reas correctas de las flores, aumentando la confianza en los resultados obtenidos.

```python
ğŸ” Aplicando GradCAM...
   PredicciÃ³n: Clase 40
   Real: Clase 40
```

![](../assets/UT3_TA2_3.png)

```python
ğŸ” Aplicando Integrated Gradients...
```

![](../assets/UT3_TA2_4.png)

## ReflexiÃ³n

Durante este trabajo se profundizÃ³ en el uso de tÃ©cnicas de data augmentation y en la aplicaciÃ³n de mÃ©todos de explicabilidad para modelos de clasificaciÃ³n de imÃ¡genes. 

Se aprendiÃ³ cÃ³mo combinar pipelines de preprocesamiento, normalizaciÃ³n y transformaciones para aumentar la diversidad del conjunto de entrenamiento, lo que es crucial al trabajar con datasets limitados o con muchas clases, como Oxford Flowers102. 

AdemÃ¡s, la implementaciÃ³n de GradCAM e Integrated Gradients permitiÃ³ comprender mejor cÃ³mo el modelo toma decisiones, identificando quÃ© regiones de la imagen influyen en la predicciÃ³n y evaluando la confiabilidad del modelo.

Es importante entender la relaciÃ³n entre la cantidad y calidad de datos, la complejidad del modelo y la robustez de las predicciones. El hecho de que el subset de entrenamiento fuese pequeÃ±o y la base convolucional se mantuviese congelada limitÃ³ el rendimiento final, reflejado en un accuracy de validaciÃ³n y test cercano al 53%. Esto evidencia que, aunque el modelo aprende patrones relevantes, todavÃ­a hay margen de mejora. Con 50 porciento de probabilidades sobre 102 clases.

Para mejorar los resultados futuros, se podrÃ­an aumentar el nÃºmero de imÃ¡genes de entrenamiento o generando mÃ¡s datos con augmentations, realizar fine-tuning de las capas superiores de la red preentrenada, probar arquitecturas, optimizar hiperparÃ¡metros como el learning rate y el batch size. Asimismo, explorar augmentations como Mixup o CutMix para mejorar la generalizaciÃ³n del modelo.

## Referencias

https://colab.research.google.com/drive/1TtwyZT2eb8AVlergPqSW4V5PZgojuW1K?usp=sharing