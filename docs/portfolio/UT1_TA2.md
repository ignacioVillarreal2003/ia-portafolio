---
title: "Pr√°ctica 2: Feature Engineering simple + Modelo base"
date: 2025-08-21
---

# Pr√°ctica 2: Feature Engineering simple + Modelo base

## Contexto

En esta pr√°ctica se trabaja con el dataset del Titanic aplicando Feature Engineering y entrenando un modelo base de clasificaci√≥n. El objetivo es mejorar la representaci√≥n de los datos mediante la creaci√≥n de nuevas variables y preparar el dataset para su uso en modelos predictivos.

Adem√°s, se construye un baseline con DummyClassifier, que sirve como referencia m√≠nima, y se compara su desempe√±o con un modelo de Regresi√≥n Log√≠stica entrenado sobre las variables originales y las nuevas features.

La actividad permite practicar conceptos clave de preprocesamiento, imputaci√≥n de valores faltantes, divisi√≥n en conjuntos de entrenamiento y prueba, y evaluaci√≥n de modelos utilizando m√©tricas como accuracy, classification report y la matriz de confusi√≥n.

## Objetivos

- Comprender la importancia del Feature Engineering para mejorar la calidad de los datos para el modelo.
- Crear nuevas variables derivadas del dataset original.
- Entrenar un modelo de Regresi√≥n Log√≠stica y evaluarlo.
- Comparar el rendimiento con un baseline.
- Analizar resultados mediante m√©tricas de clasificaci√≥n y la matriz de confusi√≥n.

## Actividades

- Investigaci√≥n de Scikit-learn
- Preprocesamiento y features
- Modelo base y baseline

## Desarrollo

### 1. Investigaci√≥n de Scikit-learn

#### LogisticRegression

- Resuelve problemas de clasificaci√≥n binaria y multiclase.
- Par√°metros importantes:
  - `penalty`: tipo de regularizaci√≥n (l1, l2).
  - `C`: controla la fuerza de regularizaci√≥n.
  - `solver`: m√©todo num√©rico de optimizaci√≥n.
- `solver='liblinear'`: √∫til para datasets peque√±os y soporta `l1`.  

#### DummyClassifier

- Genera un modelo baseline muy simple.  
- Estrategias: `most_frequent`, `stratified`, `uniform`.  
- Si un modelo complejo no supera al baseline, no es mejor que adivinar.

#### train_test_split

- `stratify=y`: mantiene la proporci√≥n de clases en train/test.  
- `random_state`: garantiza reproducibilidad.  
- Tama√±o de test: com√∫n usar 20%.

#### M√©tricas de evaluaci√≥n

- `classification_report`: incluye `precision`, `recall`, `f1-score`, `support`.
- Matriz de confusi√≥n: muestra errores en FP y FN.
- `accuracy`: buena si las clases est√°n balanceadas, si no, conviene usar `f1` o `recall`.

## 2. Preprocesamiento y Feature Engineering

Feature Engineering es transformar y crear nuevas variables que hagan m√°s f√°cil para el modelo encontrar patrones.

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

plt.style.use('seaborn-v0_8')
sns.set_palette('deep')

!pip -q install kaggle
from google.colab import files
files.upload()  # Sub√≠ tu archivo kaggle.json descargado
!mkdir -p ~/.kaggle && cp kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json
!kaggle competitions download -c titanic -p data
!unzip -o data/titanic.zip -d data

train = pd.read_csv('data/train.csv')
test = pd.read_csv('data/test.csv')

from pathlib import Path
try:
    from google.colab import drive
    drive.mount('/content/drive')
    ROOT = Path('/content/drive/MyDrive/IA-UT1')
except Exception:
    ROOT = Path.cwd() / 'IA-UT1'

DATA_DIR = ROOT / 'data'
RESULTS_DIR = ROOT / 'results'
for d in (DATA_DIR, RESULTS_DIR):
    d.mkdir(parents=True, exist_ok=True)
print('Outputs ‚Üí', ROOT)
```

```python
df = train.copy()

# üö´ PASO 1: Manejar valores faltantes (imputaci√≥n)
df['Embarked'] = df['Embarked'].fillna(df['Embarked'].mode()[0])  # Valor m√°s com√∫n
df['Fare'] = df['Fare'].fillna(df['Fare'].median())              # Mediana
df['Age'] = df['Age'].fillna(df.groupby(['Sex','Pclass'])['Age'].transform('median'))

# üÜï PASO 2: Crear nuevas features √∫tiles
df['FamilySize'] = df['SibSp'] + df['Parch'] + 1
df['IsAlone'] = (df['FamilySize'] == 1).astype(int)

df['Title'] = df['Name'].str.extract(',\s*([^\.]+)\.')
rare_titles = df['Title'].value_counts()[df['Title'].value_counts() < 10].index
df['Title'] = df['Title'].replace(rare_titles, 'Rare')

# üîÑ PASO 3: Preparar datos para el modelo
features = ['Pclass','Sex','Age','Fare','Embarked','FamilySize','IsAlone','Title','SibSp','Parch']
X = pd.get_dummies(df[features], drop_first=True)
y = df['Survived']

X.shape, y.shape
```

```python
((891, 14), (891,))
```

### 3. Modelo base y baseline

```python
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.linear_model import LogisticRegression
from sklearn.dummy import DummyClassifier

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

dummy = DummyClassifier(strategy='most_frequent', random_state=42)
dummy.fit(X_train, y_train)
baseline_pred = dummy.predict(X_test)

lr = LogisticRegression(max_iter=1000, solver='liblinear', random_state=42)
lr.fit(X_train, y_train)
pred = lr.predict(X_test)

print('Baseline acc:', accuracy_score(y_test, baseline_pred))
print('LogReg acc  :', accuracy_score(y_test, pred))

print('\nClassification report (LogReg):')
print(classification_report(y_test, pred))

print('\nConfusion matrix (LogReg):')
print(confusion_matrix(y_test, pred))
```

```python
Baseline acc: 0.6145251396648045
LogReg acc  : 0.8156424581005587

Classification report (LogReg):
              precision    recall  f1-score   support

           0       0.82      0.89      0.86       110
           1       0.80      0.70      0.74        69

    accuracy                           0.82       179
   macro avg       0.81      0.79      0.80       179
weighted avg       0.81      0.82      0.81       179


Confusion matrix (LogReg):
[[98 12]
 [21 48]]
```

## Reflexi√≥n

El modelo se equivoca m√°s al predecir que una persona sobrevivi√≥ y no lo hizo (FN - 21 casos) que al predecir que no sobrevivi√≥ cuando s√≠ lo hizo (FP - 12 casos), seg√∫n la matriz de confusi√≥n.

El modelo acierta m√°s con los que no sobrevivieron (98 aciertos) que con los que s√≠ sobrevivieron (48 aciertos).

El baseline tiene una exactitud de ~61% mientras que la Regresi√≥n Log√≠stica logra ~82%. Esto demuestra que el modelo aprende patrones √∫tiles y supera el baseline.

Los falsos negativos (predijo que no sobrevivi√≥ y s√≠ lo hizo) pueden ser errores m√°s graves si estuvieras usando el modelo para priorizar rescates, porque podr√≠an dejar sin atenci√≥n a alguien que necesitaba ayuda o pasarlo por muerto.

Respecto a la supervivencia de las personas, tanto la edad, sexo y clase fueron muy influyentes, mujeres y ni√±os primeros, ademas de los ricos de primera clase.

Alguna nueva columna que podr√≠a ayudar a que el modelo acierte m√°s serian:

- Extraer la letra de la cabina (`C23` ‚Üí `C`) para reflejar la ubicaci√≥n en el barco.
- Categorizar edades en rangos (`Child`, `Adult`, `Senior`) para capturar diferencias de supervivencia.

Como conclusiones generales, esta pr√°ctica permiti√≥ comprobar que el Feature Engineering es una herramienta fundamental, al crear variables derivadas se pueden capturar patrones y relaciones que no son evidentes en los datos originales, lo que hace que mejore la capacidad predictiva.

La comparaci√≥n con un baseline es importante, ya que brinda un punto de referencia m√≠nimo y permite confirmar que nuestro modelo realmente aporta valor y no se limita a repetir la clase mayoritaria.

Por √∫ltimo, la Regresi√≥n Log√≠stica demostr√≥ ser un modelo simple, interpretable y a la vez muy eficaz para el datasets.

## Referencias

- Dataset: https://www.kaggle.com/competitions/titanic/data/
- Kaggle: https://www.kaggle.com/
- Scikit-learn: https://scikit-learn.org/stable/
https://colab.research.google.com/drive/1ll1-Xful-SHlzc6wazeKC5QGFEbXb0O6?usp=sharing